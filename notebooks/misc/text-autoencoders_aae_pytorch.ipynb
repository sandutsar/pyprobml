{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of Copy of text_vae_all_in_one.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgaMOfMt0rLz"
   },
   "source": [
    "# Adversarial autoencoders for text\n",
    "\n",
    "### Code: https://github.com/shentianxiao/text-autoencoders\n",
    "\n",
    "### Paper: https://arxiv.org/pdf/1905.12777.pdf\n",
    "\n",
    "### GCP account creation: https://cloud.google.com/apigee/docs/hybrid/v1.1/precog-gcpaccount\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUYM4RbZ0nQh"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YDwUFHfIPUy",
    "outputId": "2fcd5db5-9df4-4e4d-f262-39a80448beb9"
   },
   "source": [
    "import torch\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "print(cpu_count())\n",
    "print(torch.cuda.is_available())"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2\n",
      "True\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBTDYua1IPYw",
    "outputId": "4827c45d-0ec5-4020-a2fb-41b693132a78"
   },
   "source": [
    "!git clone https://github.com/shentianxiao/text-autoencoders.git"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'text-autoencoders'...\n",
      "remote: Enumerating objects: 114, done.\u001b[K\n",
      "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 114 (delta 11), reused 12 (delta 4), pack-reused 83\u001b[K\n",
      "Receiving objects: 100% (114/114), 270.78 KiB | 22.56 MiB/s, done.\n",
      "Resolving deltas: 100% (56/56), done.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82JBs11jNxv1",
    "outputId": "5aa49ed8-f6c0-4b27-b6e8-40875307429b"
   },
   "source": [
    "%cd text-autoencoders"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/text-autoencoders\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIy1JfPPNx5x",
    "outputId": "37d48979-76c4-4ad0-b492-fe92e0b15d7c"
   },
   "source": [
    "!bash download_data.sh"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "--2021-07-25 06:04:40--  http://people.csail.mit.edu/tianxiao/data/yelp.zip\n",
      "Resolving people.csail.mit.edu (people.csail.mit.edu)... 128.30.2.133\n",
      "Connecting to people.csail.mit.edu (people.csail.mit.edu)|128.30.2.133|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3676642 (3.5M) [application/zip]\n",
      "Saving to: ‘yelp.zip’\n",
      "\n",
      "yelp.zip            100%[===================>]   3.51M  7.49MB/s    in 0.5s    \n",
      "\n",
      "2021-07-25 06:04:40 (7.49 MB/s) - ‘yelp.zip’ saved [3676642/3676642]\n",
      "\n",
      "Archive:  yelp.zip\n",
      "   creating: yelp/\n",
      "   creating: yelp/tense/\n",
      "  inflating: yelp/tense/valid.past   \n",
      "  inflating: yelp/tense/valid.present  \n",
      "  inflating: yelp/tense/test.past    \n",
      "  inflating: yelp/tense/test.present  \n",
      "   creating: yelp/sentiment/\n",
      "  inflating: yelp/sentiment/100.neg  \n",
      "  inflating: yelp/sentiment/100.pos  \n",
      "  inflating: yelp/sentiment/1000.neg  \n",
      "  inflating: yelp/sentiment/1000.pos  \n",
      "  inflating: yelp/test.txt           \n",
      "  inflating: yelp/train.txt          \n",
      "  inflating: yelp/valid.txt          \n",
      "   creating: yelp/interpolate/\n",
      "  inflating: yelp/interpolate/example.long  \n",
      "  inflating: yelp/interpolate/example.short  \n",
      "--2021-07-25 06:04:40--  http://people.csail.mit.edu/tianxiao/data/yahoo.zip\n",
      "Resolving people.csail.mit.edu (people.csail.mit.edu)... 128.30.2.133\n",
      "Connecting to people.csail.mit.edu (people.csail.mit.edu)|128.30.2.133|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11962156 (11M) [application/zip]\n",
      "Saving to: ‘yahoo.zip’\n",
      "\n",
      "yahoo.zip           100%[===================>]  11.41M  10.0MB/s    in 1.1s    \n",
      "\n",
      "2021-07-25 06:04:42 (10.0 MB/s) - ‘yahoo.zip’ saved [11962156/11962156]\n",
      "\n",
      "Archive:  yahoo.zip\n",
      "   creating: yahoo/\n",
      "  inflating: yahoo/test.txt          \n",
      "  inflating: yahoo/train.txt         \n",
      "  inflating: yahoo/valid.txt         \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rG97oAJdvCup"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JeOW9eT0vBse"
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from vocab import Vocab\n",
    "from model import *\n",
    "from utils import *\n",
    "from batchify import get_batches\n",
    "from train import evaluate"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoLQcAN-wZh6"
   },
   "source": [
    "# Getting the checkpoints of trained model from probml-data bucket "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xs_rWp-5HEmU"
   },
   "source": [
    "# Authentication is required to access a protected bucket. This is not required for a public one.\n",
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mai41aZaIO52"
   },
   "source": [
    "bucket_name = \"probml_data\""
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "doylC-Z0wmJP"
   },
   "source": [
    "!mkdir /content/text-autoencoders/checkpoints"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69TeHhTC9ckp"
   },
   "source": [
    "How to use [gsutil](https://cloud.google.com/storage/docs/gsutil/commands/help)  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWU46UisvJEC",
    "outputId": "9252019e-9c70-4853-858f-c92c3c4ad191"
   },
   "source": [
    "!gsutil cp -r gs://{bucket_name}/text-autoencoders/vocab.txt /content/text-autoencoders/checkpoints/"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Copying gs://probml_data/text-autoencoders/vocab.txt...\n",
      "/ [0 files][    0.0 B/100.7 KiB]                                                \r/ [1 files][100.7 KiB/100.7 KiB]                                                \r\n",
      "Operation completed over 1 objects/100.7 KiB.                                    \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwl-tQNfvtsj",
    "outputId": "2696d44b-728d-4e17-ff47-39363dfef3ab"
   },
   "source": [
    "!gsutil cp -r gs://{bucket_name}/text-autoencoders/text_ae_yelp_30_epochs.pt /content/text-autoencoders/checkpoints/"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Copying gs://probml_data/text-autoencoders/text_ae_yelp_30_epochs.pt...\n",
      "\\ [1 files][133.3 MiB/133.3 MiB]                                                \n",
      "Operation completed over 1 objects/133.3 MiB.                                    \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gD8bPHl9yJYX"
   },
   "source": [
    "# Creating vocab"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J5PB57qlRRQe"
   },
   "source": [
    "vocab = Vocab(\"/content/text-autoencoders/checkpoints/vocab.txt\")  # os.path.join(args.checkpoint, 'vocab.txt')"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vPxgjNEERRX3"
   },
   "source": [
    "seed = 1111\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "batch_size = 100\n",
    "max_len = 35"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gnHUEdKDSP0o"
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Plc0VoUyNzt"
   },
   "source": [
    "# Loading checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kNdOXogwSdkK"
   },
   "source": [
    "ckpt = torch.load(\"/content/text-autoencoders/checkpoints/text_ae_yelp_30_epochs.pt\")"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vAMhD8pwSdrq"
   },
   "source": [
    "train_args = ckpt[\"args\"]"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7q3AmmtjyRsI"
   },
   "source": [
    "# Selecting AAE model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q1kNfaynSdy8"
   },
   "source": [
    "model = {\"dae\": DAE, \"vae\": VAE, \"aae\": AAE}[\"aae\"](vocab, train_args).to(device)"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYOyYNEpSd6l",
    "outputId": "5d58c4ed-3f05-411f-a2ab-dab12f8dba47"
   },
   "source": [
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.flatten()\n",
    "model.eval()"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AAE(\n",
       "  (embed): Embedding(10005, 512)\n",
       "  (proj): Linear(in_features=1024, out_features=10005, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (E): LSTM(512, 1024, bidirectional=True)\n",
       "  (G): LSTM(512, 1024)\n",
       "  (h2mu): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (h2logvar): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (z2emb): Linear(in_features=128, out_features=512, bias=True)\n",
       "  (D): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-5_jDM1wVg23"
   },
   "source": [
    "def encode(sents, enc=\"mu\"):\n",
    "    assert enc == \"mu\" or enc == \"z\"\n",
    "    batches, order = get_batches(sents, vocab, batch_size, device)\n",
    "    z = []\n",
    "    for inputs, _ in batches:\n",
    "        mu, logvar = model.encode(inputs)\n",
    "        if enc == \"mu\":\n",
    "            zi = mu\n",
    "        else:\n",
    "            zi = reparameterize(mu, logvar)\n",
    "        z.append(zi.detach().cpu().numpy())\n",
    "    z = np.concatenate(z, axis=0)\n",
    "    z_ = np.zeros_like(z)\n",
    "    z_[np.array(order)] = z\n",
    "    return z_"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LNkoBqX5Vkg-"
   },
   "source": [
    "def decode(z, dec=\"greedy\"):\n",
    "    sents = []\n",
    "    i = 0\n",
    "    while i < len(z):\n",
    "        zi = torch.tensor(z[i : i + batch_size], device=device)\n",
    "        outputs = model.generate(zi, max_len, dec).t()\n",
    "        for s in outputs:\n",
    "            sents.append([vocab.idx2word[id] for id in s[1:]])\n",
    "        i += batch_size\n",
    "    return strip_eos(sents)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_557yqSyZng"
   },
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nQLJp0EdTn5i"
   },
   "source": [
    "n = 5\n",
    "sents = load_sent(\"/content/text-autoencoders/data/yelp/test.txt\")\n",
    "z = encode(sents)\n",
    "sents_rec = decode(z)\n",
    "write_z(z, \"/content/text-autoencoders/checkpoints/test.z\")\n",
    "write_sent(sents_rec, \"/content/text-autoencoders/checkpoints/test.rec\")"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhiM2rEx2J21",
    "outputId": "04aa001e-fe6d-4230-a0f0-0014cb9fb3e9"
   },
   "source": [
    "for i in range(n):\n",
    "    sentence = \"\"\n",
    "    rec = \"\"\n",
    "    for word in sents[i]:\n",
    "\n",
    "        sentence = sentence + word + \" \"\n",
    "    print(\"Original sentence: \" + sentence)\n",
    "\n",
    "    for word in sents_rec[i]:\n",
    "        rec = rec + word + \" \"\n",
    "    print(\"Reconstructed sentence: \" + rec)\n",
    "    print(\"\\n\")"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Original sentence: husband loves the thin crust pizza . \n",
      "Reconstructed sentence: my husband loves thin crust pizza . \n",
      "\n",
      "\n",
      "Original sentence: breadsticks are great too \n",
      "Reconstructed sentence: sausage are great too \n",
      "\n",
      "\n",
      "Original sentence: monicals pizza is by far one of my favorite pizzas . \n",
      "Reconstructed sentence: <unk> pizza is by far one of my favorite pizzas . \n",
      "\n",
      "\n",
      "Original sentence: the traditional thin crust topped with sausage and pinnaple it where its at . \n",
      "Reconstructed sentence: the little thin crust with bacon and <unk> it 's where its at . \n",
      "\n",
      "\n",
      "Original sentence: i also like this location . \n",
      "Reconstructed sentence: i also like this location . \n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DS5hxZdzb67"
   },
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nW0Sv7GFYD_1"
   },
   "source": [
    "n = 10\n",
    "dim_z = 128"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gghye6JGYEHi"
   },
   "source": [
    "z = np.random.normal(size=(n, dim_z)).astype(\"f\")\n",
    "sents = decode(z)\n",
    "write_sent(sents, \"/content/text-autoencoders/checkpoints/sample\")"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-3zBeI2_z3E",
    "outputId": "6581c3f9-512a-40b8-c1c5-e0dd6fc6066d"
   },
   "source": [
    "for i in range(n):\n",
    "    sample = \"\"\n",
    "    for word in sents[i]:\n",
    "        sample = sample + word + \" \"\n",
    "    print(sample)"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "special night with the food . \n",
      "i ordered the very chorizo . \n",
      "the pasta <unk> - three things : ) \n",
      "all are the best . \n",
      "i had a reservation and received the service . \n",
      "i <unk> will probably visit the city . \n",
      "the <unk> is . \n",
      "i think we were <unk> from <unk> with shipping . \n",
      "we 've been to several people and to the service <unk> . \n",
      "i wanted the eggs benedict and chili cheese strips . \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SZaVG6OZcgy"
   },
   "source": [
    "# Tense"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QJxMcNonQNj6"
   },
   "source": [
    "n = 10"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jsStGpwcYEbr"
   },
   "source": [
    "k = 1"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B86vq6kWYEjj"
   },
   "source": [
    "fa, fb, fc = (\n",
    "    \"/content/text-autoencoders/data/yelp/tense/valid.past\",\n",
    "    \"/content/text-autoencoders/data/yelp/tense/valid.present\",\n",
    "    \"/content/text-autoencoders/data/yelp/tense/test.past\",\n",
    ")\n",
    "sa, sb, sc = load_sent(fa), load_sent(fb), load_sent(fc)\n",
    "za, zb, zc = encode(sa), encode(sb), encode(sc)\n",
    "zd = zc + k * (zb.mean(axis=0) - za.mean(axis=0))\n",
    "sd = decode(zd)\n",
    "write_sent(sd, \"/content/text-autoencoders/checkpoints/test.past2present\")"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1l9vAKRFL_Se",
    "outputId": "1e57c2af-cbb5-492c-9881-b4ba4e2e9acd"
   },
   "source": [
    "for i in range(n):\n",
    "    tense = \"\"\n",
    "    for word in sd[i]:\n",
    "        tense = tense + word + \" \"\n",
    "    print(tense)"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "and rather than the pizza is served missing a decent . \n",
      "`` the oven '' everything 's - '' according to the waitress . \n",
      "reasonably priced . \n",
      "you ca n't be more happy with their either . \n",
      "they could use a text add , but the rice is nice . \n",
      "i got the garlic chicken with vegetables with lo mein . \n",
      "i paid over $ <unk> <unk> and it 's just pretty greasy and very bland . \n",
      "i walked in and <unk> , book , and lost me look . \n",
      "`` you have you a concert before here ? '' \n",
      "she asked , <unk> my confused <unk> . \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrGkOBNDcLFp"
   },
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kXXfrWvjHhRm"
   },
   "source": [
    "n = 10"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4-np7Cx2FRB"
   },
   "source": [
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x6h6GNiXYE5B"
   },
   "source": [
    "k = 2"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ntq-qvZdcRV8"
   },
   "source": [
    "fa, fb, fc = (\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/100.neg\",\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/100.pos\",\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/1000.neg\",\n",
    ")\n",
    "sa, sb, sc = load_sent(fa), load_sent(fb), load_sent(fc)\n",
    "za, zb, zc = encode(sa), encode(sb), encode(sc)\n",
    "zd = zc + k * (zb.mean(axis=0) - za.mean(axis=0))\n",
    "sd = decode(zd)\n",
    "write_sent(sd, \"/content/text-autoencoders/checkpoints/2_1000.neg2pos\")"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQ_r-23kMcWV",
    "outputId": "e78c080f-48d0-45c9-8352-1f563964badc"
   },
   "source": [
    "for i in range(n):\n",
    "    sentiment = \"\"\n",
    "    for word in sd[i]:\n",
    "        sentiment = sentiment + word + \" \"\n",
    "    print(sentiment)"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "the staff is both . \n",
      "this place sucks . \n",
      "we have been here for times , with family and time . \n",
      "1st time , pizza , and was great . \n",
      "wo n't go back . \n",
      "also love all the <unk> are always on . \n",
      "the food is ok , especially , <unk> , and not great location . \n",
      "it 's not worth it . \n",
      "friendly staff , but very helpful . \n",
      "we got the seafood crust and it was really very easy . \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7PDM8JE2OoJ"
   },
   "source": [
    "k = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AZ-LtsKW1tuL"
   },
   "source": [
    "k = 1.5"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_NM3bsqB1uXM"
   },
   "source": [
    "fa, fb, fc = (\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/100.neg\",\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/100.pos\",\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/1000.neg\",\n",
    ")\n",
    "sa, sb, sc = load_sent(fa), load_sent(fb), load_sent(fc)\n",
    "za, zb, zc = encode(sa), encode(sb), encode(sc)\n",
    "zd = zc + k * (zb.mean(axis=0) - za.mean(axis=0))\n",
    "sd = decode(zd)\n",
    "write_sent(sd, \"/content/text-autoencoders/checkpoints/1_5_1000.neg2pos\")"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfKqgDafMfyF",
    "outputId": "7315c162-db25-427e-ce6b-4d91a5c1b47c"
   },
   "source": [
    "for i in range(n):\n",
    "    sentiment = \"\"\n",
    "    for word in sd[i]:\n",
    "        sentiment = sentiment + word + \" \"\n",
    "    print(sentiment)"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "the answer was none . \n",
      "this place sucks . \n",
      "we have been here for times , with an family time . \n",
      "1st time , pizza , was great . \n",
      "wo n't go back . \n",
      "also love all the <unk> are closed on . \n",
      "the food is alright , especially like <unk> , and not this location . \n",
      "it 's not worth it . \n",
      "friendly staff , but very helpful . \n",
      "we got the unique crust and it was really fresh and hard . \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iyb7AuaM2ScS"
   },
   "source": [
    "k =1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GdK4IvDn2UWb"
   },
   "source": [
    "k = 1"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "89WEKt-72Uf1"
   },
   "source": [
    "fa, fb, fc = (\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/100.neg\",\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/100.pos\",\n",
    "    \"/content/text-autoencoders/data/yelp/sentiment/1000.neg\",\n",
    ")\n",
    "sa, sb, sc = load_sent(fa), load_sent(fb), load_sent(fc)\n",
    "za, zb, zc = encode(sa), encode(sb), encode(sc)\n",
    "zd = zc + k * (zb.mean(axis=0) - za.mean(axis=0))\n",
    "sd = decode(zd)\n",
    "write_sent(sd, \"/content/text-autoencoders/checkpoints/1_1000.neg2pos\")"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWCC__ZtMh5W",
    "outputId": "a5203bea-f372-4493-db60-1138e14ee526"
   },
   "source": [
    "for i in range(n):\n",
    "    sentiment = \"\"\n",
    "    for word in sd[i]:\n",
    "        sentiment = sentiment + word + \" \"\n",
    "    print(sentiment)"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "the answer was none . \n",
      "this place sucks . \n",
      "we have been here several times , with an husband each time . \n",
      "1st time , bbq pizza , was horrible . \n",
      "wo n't go back . \n",
      "also like all <unk> are closed on monday . \n",
      "the food was alright , if you like <unk> , just avoid this location . \n",
      "it 's not worth it . \n",
      "friendly staff , but not extremely helpful . \n",
      "we got the thicker crust and it was really fresh and hard . \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOmjd8wBiaYq"
   },
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t1Ofzdc2cRuC"
   },
   "source": [
    "f1, f2 = (\n",
    "    \"/content/text-autoencoders/data/yelp/interpolate/example.long\",\n",
    "    \"/content/text-autoencoders/data/yelp/interpolate/example.short\",\n",
    ")\n",
    "s1, s2 = load_sent(f1), load_sent(f2)\n",
    "z1, z2 = encode(s1), encode(s2)\n",
    "zi = [interpolate(z1_, z2_, n) for z1_, z2_ in zip(z1, z2)]\n",
    "zi = np.concatenate(zi, axis=0)\n",
    "si = decode(zi)\n",
    "write_doc(si, \"/content/text-autoencoders/checkpoints/example.int\")"
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hDiTPEXAcRlg"
   },
   "source": [
    "n = 10"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUW5a_tzMntC",
    "outputId": "f04411ed-04d3-4dbd-8d56-f151a0997714"
   },
   "source": [
    "for i in range(n):\n",
    "    interpolation = \"\"\n",
    "    for word in si[i]:\n",
    "        interpolation = interpolation + word + \" \"\n",
    "    print(interpolation)"
   ],
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "i highly recommend it and i 'll definitely be back ! \n",
      "i highly recommend it and i 'll definitely be back ! \n",
      "i highly recommend it and i 'll definitely be back ! \n",
      "i highly recommend it and i 'll definitely be back ! \n",
      "i would absolutely recommend it will be back ! \n",
      "i will definitely be back ! \n",
      "i will definitely be back ! \n",
      "i will be back ! \n",
      "i will be back ! \n",
      "i will be back ! \n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}