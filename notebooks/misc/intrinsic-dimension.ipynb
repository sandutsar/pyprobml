{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd8b95b-3333-4bfa-85a7-7819c67d9a5b",
   "metadata": {},
   "source": [
    "# Intrinsic Dimension Landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3d3fb7-3103-4d79-877e-b7e6e8ce7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import random\n",
    "from functools import partial\n",
    "from jax.scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c046e21-d909-40a4-8314-cdb03fa71da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.top\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821627ff-cb9a-4fe9-93a1-e77706b3b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082fc14-1ab4-4580-ba87-6b401f58a281",
   "metadata": {},
   "source": [
    "## Intrinsic dimension toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d160afbe-cdcc-4414-893a-ea51ed112a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 10\n",
    "y = jnp.arange(R) + 1\n",
    "\n",
    "\n",
    "def f(theta_sub, P, theta_0, y):\n",
    "    \"\"\"\n",
    "    Objective low-dimensional function takes a vector theta_sub\n",
    "    such that dim(theta_sub) < dim(theta_0). We project theta_sub\n",
    "    onto dim(theta_0), and reshape the input vector into a matrix\n",
    "    of the form (10, ?). The loss is given by summing over each row\n",
    "    of\n",
    "    \"\"\"\n",
    "    theta = P @ theta_sub + theta_0\n",
    "    y_hat = theta.reshape(10, -1).sum(axis=1)\n",
    "    return jnp.sum((y_hat - y) ** 2)\n",
    "\n",
    "\n",
    "def f_full(theta, y):\n",
    "    \"\"\"\n",
    "    Objective full-dimensional function\n",
    "    \"\"\"\n",
    "    y_hat = theta.reshape(10, -1).sum(axis=1)\n",
    "    return jnp.sum((y_hat - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ef4e903-ba07-42f6-ba9a-66c9184fde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1000\n",
    "theta_0 = jnp.zeros(D)\n",
    "f_part = partial(f_full, y=y)\n",
    "res = minimize(f_part, theta_0, method=\"bfgs\")\n",
    "optimal_loss = res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45c1d9a-3da1-40c3-8485-35dbc29c8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(314)\n",
    "\n",
    "d = 10\n",
    "R = 10\n",
    "\n",
    "theta_0 = random.normal(key, (D,)) / 10\n",
    "theta_sub_0 = jnp.zeros(d)\n",
    "\n",
    "choice_map = random.bernoulli(key, 1 / jnp.sqrt(D), shape=(D, d))\n",
    "P = random.choice(key, jnp.array([-1, 1]), shape=(D, d)) * choice_map\n",
    "P = P / jnp.linalg.norm(P, axis=0)\n",
    "\n",
    "M = jnp.ones((R, D))\n",
    "f_part = partial(f, P=P, theta_0=theta_0, y=y)\n",
    "res = minimize(f_part, theta_sub_0, method=\"bfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19239d4-bd82-46c6-9f99-9f3de2e7e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_subspace(key, d):\n",
    "    key_weight, key_map, key_sign = random.split(key, 3)\n",
    "    theta_0 = random.normal(key_weight, (D,)) / 10\n",
    "    theta_sub_0 = jnp.zeros(d)\n",
    "\n",
    "    choice_map = random.bernoulli(key_map, 1 / jnp.sqrt(D), shape=(D, d))\n",
    "    P = random.choice(key_sign, jnp.array([-1, 1]), shape=(D, d)) * choice_map\n",
    "    f_part = partial(f, P=P, theta_0=theta_0, y=y)\n",
    "    res = minimize(f_part, theta_sub_0, method=\"bfgs\", tol=1e-3)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302cc4cd-8cc2-47f3-bbc0-e3e02e307f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(314)\n",
    "\n",
    "dimensions = jnp.array(list(range(1, 16)) + [20, 30, 40])\n",
    "keys = random.split(key, len(dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b803220-e238-492d-bab4-786ace18119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.2 s, sys: 922 ms, total: 40.2 s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ans = {\"dim\": [], \"loss\": [], \"w\": []}\n",
    "\n",
    "for key, dim in zip(keys, dimensions):\n",
    "    print(f\"@dim={dim}\", end=\"\\r\")\n",
    "    res = optimize_subspace(key, dim)\n",
    "    ans[\"dim\"].append(dim)\n",
    "    ans[\"loss\"].append(res.fun)\n",
    "    ans[\"w\"].append(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcff481-d8a0-4eed-8859-29337f863a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7aa3e65700>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAHwCAYAAAD0N5r7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAABYlAAAWJQFJUiTwAAAuCElEQVR4nO3dfbTld10f+vdnMgmTCSFIUsKqUPNAJuH60DpgAowiSWyMerWI4urymtosEal4ExHXlfpEQssq3q7yEAraapGitnrrA1wtV6IxFpyA2MHHCuSBDGANwSSYhsw5yUzme//Y+0z2OTn7nH322Q+/M/v1Wuus35n927/f/uaX7z7znu/5/D67WmsBAAC6Yde8BwAAADxOQAcAgA4R0AEAoEMEdAAA6BABHQAAOkRABwCADhHQAQCgQwR0AADoEAEdAAA6REAHAIAOEdABAKBDBHQAAOiQhQroVfVLVfVL8x4HAAAMs3veA5ixS/bv378/yXfOeyAAAJz0apyDFmoFHQAAuk5ABwCADhHQAQCgQwR0AADoEAEdAAA6REAHAIAOEdABAKBDBHQAAOgQAR0AADpEQAcAgA4R0AEAoEN2z3sAwGq33/tQDt55X76wfCxP3rM7B559Tvade+ZMjl/U115krhuzZL4xSzt5vgno0BEH77wvb73ljnzk7geesO/S85+W66+8KAeefc5Ujl/U115krhuzZL4xSyfDfKvW2vZPUvXtSb42yT9I8veTnJnkl1pr3zXGuZ6Z5PVJrk5ydpJ7krwnyY2ttc9vc5yH9u/fv//QoUPbOQ1M3K/80afzz3/9z3N8g7fjrkre+NKvyHd81bMmevyivvYic92YJfONWergfKtxDppUDfqPJ/mB9AL6/xz3JFV1YZJDSa5N8pEkb07yySTXJ/lQVZ297ZFCxxy8875Nf5gkyfGWvPbX/ywH77xvYscv6msvMteNWTLfmKWTab5NKqC/Osm+JE9J8s+2cZ53JHl6kutaay9prb22tXZFekH94iRv2PZIoWPeessdm/4wWXG8JTfdcsfEjl/U115krhuzZL4xSyfTfJtIDXpr7daV76vGWslPVV2Q5Kokh5O8fc3u1yV5RZJrquo1rbWHxxspdMvt9z60bo3cRv7w7gfysXv+V/ade+a2jk+ykK+9U24QmgbXjVky35ilcefb7fc+1Mn5NpEa9FUnrHpxkluzxRr0qnp5kp9N8u9ba9+3zv73pxfgv661dssm5xpWZH7J/v3796pBpyt+/uDdufE3/3LewwCAhfS6b/7fcu2B86f5EnOtQZ+Ei/vb24fsX/k9xL4ZjAVm4gvLx+Y9BABYWF39e7hLbRbP6m8fHLJ/5fGnbnai1tpz13u8v7K+f8sjgyl58p7x3oKVpCppLRnnd2Ar/5wf99id/NpjVuGdFFw3Zsl8Y5bGnW/j/j08bd0c1fq28/c6dNK4fVjf/+oXnajFvurNHxjr+CRjH7uTX7uLtYaz4roxS+YbszTufOtqP/QulbisrJCfNWT/U9Y8D3a8feeemUvPf9qWjrns/Ked+MtrO8cv6msvMteNWTLfmKWTbb51KaB/or8dVmN+UX87rEYddqTrr7wou0b8de6uSq678qJVj23n+EV97UXmujFL5huzdDLNty4F9JVWjVdV1apxVdWZSQ4kWUry4VkPDKbpwLPPyb966Zdv+kNl5ZPP1v46bjvHL+prLzLXjVky35ilk2m+zbzNYlWdmuTCJEdba3et2bfSSvG61trbBh5/U3ofhvTvWmuv3MbYDu3fv3+/Not00cE778tNt9yRP1ynj+tl5z8t11150YY/TLZz/KK+9iJz3Zgl841Z6th8G+uW54kE9Kp6SZKX9P/4jCRfn+STST7Yf+y+1toP9597XpK7k3yqtXbemvNcmOS29D5N9L1JPpbksiSXp1fa8sLW2v3bGKeATud920/flkOf+nyS5Dsv+3v5py88b0s1crff+1AO3nlfvrB8LE/eszsHnn3OyMdv59id/NqLzHVjlsw3Zqkj822uAf2G9D7tc5gTYXyjgN7f/6wkr09ydZKzk9yT5D1Jbmytbe0jop54bgGdzvuOn/lQPnK4N9V/+RXPz/MvOHvOIwIAxjRWQJ9Im8XW2g1JbhjxuYezwWBba59Jcu0kxgU70dLRx058f/qpp8xxJADAPHTpJlEgawL6aQI6ACwaAR06ZulRK+gAsMgEdOgYK+gAsNgEdOgYK+gAsNgEdOiQ1tqqFfQ9AjoALBwBHTrkkWPHT3x/2u5dOWXUzywGAE4aAjp0iPIWAEBAhw7RAx0AENChQ3RwAQAEdOiQwRIXN4gCwGIS0KFDlgdW0PdaQQeAhSSgQ4cccZMoACw8AR06RA90AEBAhw5ZdpMoACw8AR06ZHUfdG9PAFhEEgB0iD7oAICADh2yqgZdiQsALCQBHTpkWRcXAFh4Ajp0iBIXAEBAhw5Z0sUFABaegA4dsvTo8RPfW0EHgMUkoEOHLB09duJ7K+gAsJgEdOiQJTeJAsDCE9ChQ9wkCgAI6NAhS0cfr0HXBx0AFpOADh2iDzoAIKBDhyhxAQAEdOgQfdABAAEdOmSwxGWPFXQAWEgCOnTI4Ar6XivoALCQBHToiEePHc+x4y1JsntX5dRTvD0BYBFJANARbhAFABIBHTpjeSCg64EOAItLQIeOWNIDHQCIgA6docQFAEgEdOiMJSUuAEAEdOiM5VUlLt6aALCopADoCCUuAEAioENnrP6Qot1zHAkAME8COnTEYBeXPVbQAWBhCejQEatKXE7z1gSARSUFQEfogw4AJAI6dIabRAGARECHztAHHQBIBHTojGUlLgBABHToDCUuAEAioENnLB09fuL705W4AMDCEtChI/RBBwASAR06Y3nVJ4kK6ACwqAR06Igjjx478b0adABYXAI6dMRgDboSFwBYXAI6dMRgiYubRAFgcQno0BFL+qADABHQoTP0QQcAEgEdOmNJiQsAEAEdOuGx4y2PHnv8JtEn7fbWBIBFJQVAByyvKW+pqjmOBgCYJwEdOmDJhxQBAH0COnTAYAcXPdABYLEJ6NABbhAFAFYI6NABeqADACsEdOgAPdABgBUCOnTAYEDfo8QFABaagA4dsLyqxMXbEgAW2cSSQFU9s6reWVV/XVWPVNXhqnpLVX3RFs/zTVV1c1X9VVUtVdUnq+q/VNULJjVW6BolLgDAiokE9Kq6MMmhJNcm+UiSNyf5ZJLrk3yoqs4e8Tw/leS3kuxP8ttJ3prko0n+UZKDVfVdkxgvdI0uLgDAit0TOs87kjw9yXWttbetPFhVb0ry6iRvSPLKjU5QVc9I8sNJ7k3yFa21zw3suzzJ7yV5fZJfnNCYoTNWd3GZ1NsSANiJtr2CXlUXJLkqyeEkb1+z+3VJHk5yTVWdscmpvqQ/nj8cDOdJ0lq7NclDSf7OdscLXbS8agVdDToALLJJJIEr+tubW2vHB3e01h5KcjDJ3iTP3+Q8dyR5NMmlVXXO4I6qelGSM5P87gTGC51zRB90AKBvEr9Lv7i/vX3I/jvSW2Hfl+SWYSdprT1QVT+S5E1J/rKq3pPk/iQXJvmWJL+T5PtGGVBVHRqy65JRjodZW9VmUUAHgIU2iYB+Vn/74JD9K48/dbMTtdbeUlWHk7wzyfcO7LozybvWlr7AyWLZTaIAQN8sil2rv22bPrHq/0ryq0neld7K+RlJnpteR5hfqqr/e5QXbK09d72vJB8f5z8Apm1JiQsA0DeJgL6yQn7WkP1PWfO8dVXVi5P8VJL/t7X2Q621T7bWjrTWPprkW5P8zySv6d+UCicVfdABgBWTCOif6G/3Ddl/UX87rEZ9xf/e3966dkdr7Uh6/dV3JfnKrQ4Qum7p6OP3V+9R4gIAC20SAX0lUF9VVavOV1VnJjmQZCnJhzc5z5P622GtFFcef3ScQUKXLStxAQD6th3QW2t3Jbk5yXlJXrVm943p1ZG/u7X2cJJU1alVdUn/00cHfbC/fUVVffHgjqr6hvSC/nKS27Y7ZugaJS4AwIpJfWTh96cXnG+qqiuTfCzJZUkuT6+05ccGnvvF/f2fSi/Ur/jV9Pqcf12Sj1XVbyT5bJLnpFf+Ukle21q7f0Jjhs4YDOh7lbgAwEKbSEBvrd1VVc9L8vokVyf5xiT3JLkpyY2ttQdGOMfxqvrG9Fbh/3F6N4buTfJAkvcluam1dvMkxgtdM9jFRR90AFhsk1pBT2vtM0muHeF5h/N468W1+44meUv/CxbGkj7oAEDfLPqgA5vQBx0AWCGgw5y11latoCtxAYDFJqDDnD1y7PEe6Kft3pVTdq1bAQYALAgBHeZMeQsAMEhAhznTAx0AGCSgw5zp4AIADBLQYc6UuAAAgwR0mLNlK+gAwAABHebsiBV0AGCAgA5zpgc6ADBIQIc5U+ICAAwS0GHOVt8k6i0JAItOGoA50wcdABgkoMOcrapBV+ICAAtPQIc5W9bFBQAYIKDDnClxAQAGCegwZ4MBfa8SFwBYeAI6zNngBxXpgw4ACOgwZ/qgAwCDBHSYsyU3iQIAAwR0mDM3iQIAgwR0mLOlo8dPfK8POgAgoMOc6YMOAAwS0GHOlLgAAIMEdJizJV1cAIABAjrM2aoSFwEdABaegA5z1FrLESUuAMAAAR3m6OhjLY8db0mS3bsqp57iLQkAi04agDlygygAsJaADnO0PBDQ9UAHABIBHeZqSQ90AGANAR3mSIkLALCWgA5ztKTEBQBYQ0CHOVrVA/1Ub0cAQECHuRpcQd972u45jgQA6AoBHeZIDToAsJaADnN0ZKDEZY+ADgBEQIe5GuyDfvpp3o4AgIAOc6UPOgCwloAOc6QGHQBYS0CHOdIHHQBYS0CHOVpW4gIArCGgwxwpcQEA1hLQYY6Wjh4/8f3pSlwAgAjoMFe6uAAAawnoMEdLR4+d+N4KOgCQCOgwV1bQAYC1BHSYo8Ea9D0COgAQAR3manmwi4sSFwAgAjrMlRIXAGAtAR3mSB90AGAtAR3maEmJCwCwhoAOc/LY8ZZHj/VuEq1KnrTb2xEAENBhbpbXlLdU1RxHAwB0hYAOc3LEDaIAwDoEdJiTwRV0PdABgBUCOsyJG0QBgPUI6DAneqADAOsR0GFO9EAHANYjoMOcDAb0PUpcAIA+AR3mZHlViYu3IgDQIxXAnChxAQDWI6DDnOjiAgCsR0CHOVndxWX3HEcCAHTJxAJ6VT2zqt5ZVX9dVY9U1eGqektVfdEY5/qaqvq1qrqnf657qurmqvrGSY0X5m1VQD/Nv5UBgJ6JLNtV1YVJbkvy9CTvTfLxJJcmuT7J1VV1oLV2/4jn+vEk/yLJfUl+K8k9Sc5J8pVJXpzkfZMYM8ybGnQAYD2T+r36O9IL59e11t628mBVvSnJq5O8IckrNztJVb0svXD+u0le2lp7aM3+Uyc0Xpi7VW0WBXQAoG/bv1evqguSXJXkcJK3r9n9uiQPJ7mmqs7Y5Dy7kvxUkiNJvnNtOE+S1trR7Y4XumLZTaIAwDomUfh6RX97c2vt+OCOfsg+mGRvkudvcp4XJjk/vRKWz1fVN1XVj1TV9VX1ggmMEzpl9U2iAjoA0DOJEpeL+9vbh+y/I70V9n1JbtngPF/V396b5KNJvnxwZ1V9IMm3t9b+ZrMBVdWhIbsu2exYmBU16ADAeiaxgn5Wf/vgkP0rjz91k/M8vb99ZZLTk3xdkjOTfFmS9yd5UZL/MvYooWOWjj7+C6c9SlwAgL5ZNF+u/rZt8ryVhFLprZT/af/P/6OqvjW9FfqvraoXtNY+tNGJWmvPXXcgvZX1/aMNG6ZrWYkLALCOSaygr6yQnzVk/1PWPG+Yz/e3nxwI50mS1tpSeqvoSa99I+x4gyUue62gAwB9kwjon+hv9w3Zf1F/O6xGfe15/nbI/pUAf/pow4JuO/LosRPfW0EHAFZMIqDf2t9e1W+VeEJVnZnkQJKlJB/e5DwfSHIsyUVVddo6+7+svz08/lChO5YHa9AFdACgb9sBvbV2V5Kbk5yX5FVrdt+Y5Iwk726tPZz0Pmyoqi7pf/ro4HnuS/Ir6ZXK/OTgvqr6h0m+Pr0ymd/e7pihC5b0QQcA1jGpm0S/P8ltSW6qqiuTfCzJZUkuT6+05ccGnvvF/f2fSi/UD/qh/nE/VlUvSvKRJF+S5FuTPJbke1trfzuhMcNc6YMOAKxnEiUuK6voz0vyrvQC9muSXJjkpiQvaK3dP+J5Ptc//s1JnpXkuvQ+COm/Jvma1po2i5wUWmurVtCVuAAAKybWZrG19pkk147wvMN5vPXievsfSG8l/YcmNTbomkeOPV5/ftruXTll19C3BACwYCaygg5sjfIWAGAYAR3mYNUNogI6ADBAQIc58CFFAMAwAjrMwWCJixtEAYBBAjrMgR7oAMAwAjrMgZtEAYBhBHSYAz3QAYBhBHSYg2UlLgDAEAI6zMHqEhdvQwDgcZIBzIE+6ADAMAI6zMGqGnQlLgDAAAEd5mBZFxcAYAgBHebAJ4kCAMMI6DAHR6ygAwBDCOgwB/qgAwDDCOgwB/qgAwDDCOgwB0tKXACAIQR0mAN90AGAYQR0mIOlo8dPfK8POgAwSECHOdAHHQAYRkCHOVDiAgAMI6DDHPigIgBgGAEd5mCwi4sadABgkIAOM9ZaU+ICAAwloMOMHX2s5bHjLUmye1fl1FO8DQGAx0kGMGNWzwGAjQjoMGPLR9WfAwDDCegwY0t6oAMAGxDQYcaUuAAAGxHQYcaWlLgAABsQ0GHGlgdKXPZaQQcA1hDQYcZWlbhYQQcA1hDQYcaOuEkUANiAgA4ztqoGXUAHANYQ0GHGlleVuHgLAgCrSQcwY/qgAwAbEdBhxvRBBwA2IqDDjOmDDgBsRECHGVtW4gIAbEBAhxlT4gIAbERAhxlbOnr8xPc+qAgAWEtAhxlbevTYie+toAMAawnoMGOrSlysoAMAawjoMGP6oAMAGxHQYcYGa9D3COgAwBoCOszYshIXAGADAjrMmBIXAGAjAjrMmD7oAMBGBHSYMV1cAICNCOgwQ48db3n0WO8m0arkSbu9BQGA1aQDmKHlNeUtVTXH0QAAXSSgwwwdcYMoALAJAR1maHAFXQ90AGA9AjrMkBtEAYDNCOgwQ3qgAwCbEdBhhvRABwA2I6DDDA0G9D1KXACAdQjoMEPLq0pcvP0AgCeSEGCGlLgAAJsR0GGGVndx2T3HkQAAXSWgwwzp4gIAbEZAhxlaFdBP8/YDAJ5IQoAZUoMOAGxGQIcZWtVmUUAHANYxsYBeVc+sqndW1V9X1SNVdbiq3lJVX7SNc15TVa3/9fJJjRXmZXnVTaICOgDwRBNpI1FVFya5LcnTk7w3yceTXJrk+iRXV9WB1tr9Wzzns5K8LckXkjx5EuOEeXOTKACwmUmtoL8jvXB+XWvtJa2117bWrkjy5iQXJ3nDVk5WVZXk55Pcn+RnJjRGmDs16ADAZrYd0KvqgiRXJTmc5O1rdr8uycNJrqmqM7Zw2uuSXJHk2v7xcFJYOnr8xPd7lLgAAOuYxAr6Ff3tza2144M7WmsPJTmYZG+S549ysqp6TpI3Jnlra+0DExgfdMbyQInLXivoAMA6JlGDfnF/e/uQ/Xekt8K+L8ktG52oqnYn+YUkn07yo+MOqKoODdl1ybjnhEk4cvTYie/dJAoArGcSAf2s/vbBIftXHn/qCOf6ySRfmeSrW2tL2xwXdI6bRAGAzUyki8smqr9tGz6p6tL0Vs3/TWvtQ9t5wdbac4e8xqEk+7dzbtiO5cEadAEdAFjHJGrQV1bIzxqy/ylrnvcEA6Uttyf5iQmMCTppSR90AGATkwjon+hv9w3Zf1F/O6xGPen1Od+X5DlJlgc+nKil1wkmSX62/9hbtjtgmBclLgDAZiZR4nJrf3tVVe0a7ORSVWcmOZBkKcmHNzjHI0n+w5B9+9OrS/+D9P4xsK3yF5iX1tqqFXQlLgDAerYd0Ftrd1XVzel1anlVep/+ueLGJGck+XettYeTpKpOTXJhkqOttbv651hK8vL1zl9VN6QX0P9ja+3ntjtemJdHjj1ef37a7l05ZVdt8GwAYFFN6ibR709yW5KbqurKJB9LclmSy9Mrbfmxged+cX//p5KcN6HXh85T3gIAjGISNejpr4Q/L8m70gvmr0lvlfymJC9ord0/ideBnWywvGWvG0QBgCEm1maxtfaZJNeO8LzDebz14ijnvSHJDeOOC7piVQcXK+gAwBATWUEHNjdY4uIGUQBgGAEdZkQPdABgFAI6zIibRAGAUQjoMCN6oAMAoxDQYUaWlbgAACMQ0GFGVpe4eOsBAOuTEmBGtFkEAEYhoMOMrKpBV+ICAAwhoMOMLA+UuOw9dWKfEQYAnGQEdJiRI4M16Kd56wEA65MSYEbUoAMAoxDQYUb0QQcARiGgw4zogw4AjEJAhxlZ3QddQAcA1iegw4yoQQcARiGgw4wsHT1+4nt90AGAYQR0mJFlJS4AwAgEdJiRwRKXvVbQAYAhBHSYkSNW0AGAEQjoMCODbRbVoAMAwwjoMAOtNV1cAICRCOgwA0cfa3nseEuS7N5VOfUUbz0AYH1SAsyA1XMAYFQCOsyA+nMAYFQCOszAkg4uAMCIBHSYASUuAMCoBHSYgSUlLgDAiAR0mIHlgRKXvVbQAYANCOgwA6s+RdQKOgCwAQEdZkANOgAwKgEdZmBVDbqADgBsQECHGRjsg376ad52AMBwkgLMgD7oAMCoBHSYATXoAMCoBHSYAX3QAYBRCegwA8tKXACAEQnoMAODK+h7raADABsQ0GEGBj+oSJtFAGAjAjrMwLKbRAGAEQnoMAOrurgocQEANiCgwwzogw4AjEpAhxlYOnr8xPdq0AGAjQjoMAPLSlwAgBEJ6DADSlwAgFEJ6DADS7q4AAAjEtBhBnRxAQBGJaDDlD12vOXRY72bRKuSJ+32tgMAhpMUYMrWlrdU1RxHAwB0nYAOU+YGUQBgKwR0mLLBFot6oAMAmxHQYcrcIAoAbIWADlOmxAUA2AoBHaZMD3QAYCsEdJiywYC+R4kLALAJAR2mbHlViYu3HACwMWkBpmxwBX3vabvnOBIAYCcQ0GHKjjyqzSIAMDoBHaZs2U2iAMAWCOgwZavaLJ7mLQcAbExagCnTZhEA2AoBHaZsVZtFAR0A2ISADlO2qgZdH3QAYBMCOkzZqhp0K+gAwCYEdJgyNegAwFZMLKBX1TOr6p1V9ddV9UhVHa6qt1TVF414/NlV9fKq+o2qurOqlqrqwar6g6r6nqryjwl2pKWjx098r8QFANjMRD7WsKouTHJbkqcneW+Sjye5NMn1Sa6uqgOttfs3Oc3Lkvx0knuS3Jrk00nOTfLSJD+X5Buq6mWttTaJMcOsLD167MT3VtABgM1M6nPH35FeOL+utfa2lQer6k1JXp3kDUleuck5bk/yLUn+a2vtxJJjVf1oko8k+bb0wvqvTWjMMBNLbhIFALZg22UjVXVBkquSHE7y9jW7X5fk4STXVNUZG52ntfZ7rbXfHAzn/cc/m+Rn+n988XbHC7PmJlEAYCsmUdd9RX978zrh+qEkB5PsTfL8bbzG0f722IbPgg5aHqhB1wcdANjMJEpcLu5vbx+y/470Vtj3Jbllqyevqt1J/kn/j7894jGHhuy6ZKuvD9ulxAUA2IpJrKCf1d8+OGT/yuNPHfP8b0zyZUne11p7/5jngLlR4gIAbMWkbhLdSPW3W+6+UlXXJXlNel1hrhn1uNbac4ec71CS/VsdB4yrtbZqBV2JCwCwmUmsoK+skJ81ZP9T1jxvJFX1qiRvTfKXSS5vrT0w3vBgfh459nj9+Wm7d+WUXbXBswEAJhPQP9Hf7huy/6L+dliN+hNU1Q8m+bdJ/iK9cP7ZsUcHczRY3rJX/TkAMIJJBPRb+9ur1n7aZ1WdmeRAkqUkHx7lZFX1I0nenORP0gvnn5vAGGEuVt0gqrwFABjBtgN6a+2uJDcnOS/Jq9bsvjHJGUne3Vp7OEmq6tSquqT/6aOrVNVPpHdT6KEkV7bW7tvu+GCejrhBFADYokndJPr9SW5LclNVXZnkY0kuS3J5eqUtPzbw3C/u7/9UeqE+SVJV353k9UkeS/LBJNdVPaFe93Br7V0TGjNM3bIbRAGALZpIQG+t3VVVz0svYF+d5BuT3JPkpiQ3jniD5/n97SlJfnDIc/5bkndta7AwQ3qgAwBbNbE2i621zyS5doTnHc7jrRcHH78hyQ2TGg90gR7oAMBWTeImUWAIPdABgK0S0GGKlpW4AABbJKDDFK0ucfF2AwA2JzHAFOmDDgBslYAOU7S6i8vE7skGAE5iAjpMkS4uAMBWCegwRasC+mnebgDA5iQGmCI16ADAVgnoMEX6oAMAWyWgwxTpgw4AbJWADlPkJlEAYKsEdJgiNegAwFYJ6DBFS0ePn/h+jxIXAGAEAjpM0fJAicteAR0AGIGADlOkxAUA2CoBHaboiJtEAYAtEtBhigbbLKpBBwBGIaDDlLTWlLgAAFsmoMOUHH2s5bHjLUmye1fl1FO83QCAzUkMMCVWzwGAcQjoMCXqzwGAcQjoMCVLOrgAAGMQ0GFKlLgAAOMQ0GFKVgV0JS4AwIgEdJgSJS4AwDgEdJiSVQHdCjoAMCIBHaZEDToAMA4BHaZkMKDvEdABgBEJ6DAly6tuEvVWAwBGIzXAlLhJFAAYh4AOU6IGHQAYh4AOU7KqBl0XFwBgRAI6TMnyQInLXivoAMCIBHSYkiP6oAMAYxDQYUq0WQQAxiGgw5Qsu0kUABiDgA5TsqqLixIXAGBEAjpMiT7oAMA4BHSYkqWjx098rwYdABiVgA5TsqzEBQAYg4AOU6LEBQAYh4AOUzJ4k+heK+gAwIgEdJgSfdABgHEI6DAFjx1vefRY7ybRquRJu73VAIDRSA0wBUtrPqSoquY4GgBgJxHQYQrcIAoAjEtAhylYVn8OAIxJQIcpWNIDHQAYk4AOU6DEBQAYl4AOU7D2JlEAgFEJ6DAFq3qgK3EBALZAQIcpWB4ocdlrBR0A2AIBHabgyKNuEgUAxiOgwxQsabMIAIxJQIcpWHaTKAAwJgEdpmBVm8XTvM0AgNFJDjAF2iwCAOMS0GEK1KADAOMS0GEKVtWg6+ICAGyBgA5TsKoG3Qo6ALAFAjpMwWCJy14r6ADAFgjoMAWDH1SkBh0A2AoBHaZAH3QAYFy75z2ARXD7vQ/l4J335QvLx/LkPbtz4NnnZN+5Z0792J382jt57Lff+1D+6vNHTvz5bx56ZOTXBQCYWECvqmcmeX2Sq5OcneSeJO9JcmNr7fOzPk8XHLzzvrz1ljvykbsfeMK+S89/Wq6/8qIcePY5Ez92J7/2Th77sGN/4D//cd794U9t+toAAElSrbXtn6TqwiS3JXl6kvcm+XiSS5NcnuQTSQ601u6f1Xk2OP+h/fv37z906NC4pxjZr/zRp/PPf/3Pc3yDy7urkje+9CvyHV/1rIkdu5NfeyePfbuvDQCclGqcgyZVg/6O9EL1da21l7TWXttauyLJm5NcnOQNMz7PXB28875Nw1qSHG/Ja3/9z3LwzvsmcuxOfu2dPPbtvjYAwKBtB/SquiDJVUkOJ3n7mt2vS/Jwkmuq6oxZnKcL3nrLHZuGtRXHW3LTLXdM5Nid/NrbPX4nvzYAwKBtl7hU1cuT/GySf99a+7519r8/veD9da21W6Z9nk3GOvUSl9vvfShXvfkDWz7uay46O0nywTu2XsHzNRednTP3nJqHlo+Offw8X3snj33c17751S/a0k2rAMCONFaJyyRuEr24v719yP470gvW+5JsFKwndZ5U1bAEfslGx03CuOUL44S8SRy7k197u8fP87UP3nmfgA4ArGsSNehn9bcPDtm/8vhTZ3SeufrC8rF5D4EdwDwBAIaZRR/0laX97baLGfk8rbXnrnuC3sr6/m2OY0NP3jPeJf325z4zSfKrh/5qrGMvv/jpufUTnxv7+Hm+9k4e+7ivPe48AQBOfpNICSsr22cN2f+UNc+b9nnmatw+16940QVJxgt7r3jRBdl37pm56Nwnj338PF97J4993NfWDx0AGGYSJS6f6G/3Ddl/UX87rLZ80ueZq33nnplLz3/alo657PynZd+5Z27r2J382ts9fie/NgDAWpMI6Lf2t1dV1arzVdWZSQ4kWUry4RmdZ+6uv/Ki7Brxnt1dlVx35UUn/rydY3fya2/3+J382gAAg7Yd0FtrdyW5Ocl5SV61ZveNSc5I8u7W2sNJUlWnVtUl/U8NHfs8XXbg2efkX730yzcNbSufLDlY7rCdY3fya+/ksW/3tQEABm27D3qS9MP2bel9Cuh7k3wsyWVJLk+vJOWFrbX7+889L8ndST7VWjtv3POMOc6p90EfdPDO+3LTLXfkD+9+4An7Ljv/abnuyouGhrXtHLuTX3snj327rw0AnHTG6oM+kYCeJFX1rCSvT3J1krOT3JPkPUlubK09MPC88zIkoG/lPGOOcaYBfcXt9z6Ug3fely8sH8uT9+zOgWefM3IN8naO3cmvvZPHvt3XBgBOGvMN6DvBvAI6AAALaayAPombRAEAgAkR0AEAoEMEdAAA6BABHQAAOkRABwCADhHQAQCgQwR0AADoEAEdAAA6REAHAIAOEdABAKBDqrU27zHMTFXdf/rppz/tOc95zryHAgDASe6jH/3of2qt/R9bPW7RAvrdSZ6S5PAYh1/S3358YgNaDK7beFy38bhu43HdxuO6jcd1G4/rNp55X7ePC+hTVFWHkqS19tx5j2Uncd3G47qNx3Ubj+s2HtdtPK7beFy38ezU66YGHQAAOkRABwCADhHQAQCgQwR0AADoEAEdAAA6RBcXAADoECvoAADQIQI6AAB0iIAOAAAdIqADAECHCOgAANAhAjoAAHSIgA4AAB0ioG+iqp5ZVe+sqr+uqkeq6nBVvaWqvmjeY+uq/jVqQ74+O+/xzVNVfXtVva2qPlhV/6t/TX5xk2NeWFXvq6oHqupIVf1ZVf1gVZ0yq3F3wVauXVWdt8EcbFX1y7Me/zxU1dlV9fKq+o2qurOqlqrqwar6g6r6nqpa9++ARZ9zW71u5tvjquqnquqWqvpM/7o9UFV/XFWvq6qzhxyz0PMt2dp1M982VlXXDFyLlw95Tufn3O55D6DLqurCJLcleXqS9yb5eJJLk1yf5OqqOtBau3+OQ+yyB5O8ZZ3HvzDjcXTNjyf5++ldh79KcslGT66qf5Tk15IsJ/mVJA8k+eYkb05yIMnLpjnYjtnStev70yTvWefxv5jcsDrtZUl+Osk9SW5N8ukk5yZ5aZKfS/INVfWyNvCJdeZckjGuW9+iz7ckeXWSjyb5nSSfS3JGkucnuSHJK6rq+a21z6w82Xw7YUvXrc98W6OqnpXkben9PfHkIc/ZGXOuteZryFeS9ydpSf7PNY+/qf/4z8x7jF38SnI4yeF5j6OLX0kuT3JRkkry4v48+sUhz31Kej+oH0nyvIHH96T3D8eW5B/P+7+po9fuvP7+d8173HO+Zlek9xfPrjWPPyO90NmSfNvA4+bceNfNfBuYK0Mef0P/Gr1j4DHzbbzrZr6tf60qye8muSvJv+5fo5evec6OmXNKXIaoqguSXJVe2Hz7mt2vS/Jwkmuq6owZD40drLV2a2vtjtb/ibCJb0/yd5L8cmvtvw+cYzm91eQk+WdTGGYnbfHakaS19nuttd9srR1f8/hnk/xM/48vHthlzmWs60Zff66s5//pby8aeMx869vidWN916X3j+tr08to69kxc06Jy3BX9Lc3r/ND+qGqOphegH9+kltmPbgd4ElV9V1J/l56b5Q/S/KB1tpj8x3WjrIyB397nX0fSHIkyQur6kmttUdmN6wd5e9W1fclOTvJ/Uk+1Fr7szmPqSuO9rfHBh4z5za33nVbYb4N98397eD1MN82t951W2G+9VXVc5K8MclbW2sfqKorhjx1x8w5AX24i/vb24fsvyO9gL4vAvp6npHkF9Y8dndVXdta+2/zGNAONHQOttaOVdXdSb40yQVJPjbLge0g/7D/dUJV/X6S726tfXouI+qAqtqd5J/0/zj4F5U5t4ENrtsK862vqn44vRrgs5I8L8lXpxcy3zjwNPNtjRGv2wrzLSfel7+QXvnZj27y9B0z5wT04c7qbx8csn/l8adOfyg7zs8n+WCS/5HkofQm+g8keUWS/6+qXtBa+9M5jm+nMAfHdyTJv0jvBqpP9h/7ivRuuLo8yS1V9Q9aa8N+DXqye2OSL0vyvtba+wceN+c2Nuy6mW9P9MPp3Vi74reT/NPW2t8MPGa+PdEo1818W+0nk3xlkq9urS1t8twdM+fUoI+v+lv1sGu01m7s13De21o70lr7i9baK9O7ufb09H6IsH3m4BCttc+11n6ytfbR1trf9r8+kN5vvf4wybOTrNt+62RXVdcleU16Xamu2erh/e3CzbmNrpv59kSttWe01iq936a+NL2Fmj+uqv1bOM3CzbdRrpv59riqujS9VfN/01r70CRO2d/Ofc4J6MOt/CvqrCH7n7LmeWxu5eaqF811FDuHOThhrbVj6bXJSxZwHlbVq5K8NclfJrm8tfbAmqeYc+sY4bqta9HnW5L0F2p+I73weHaSdw/sNt+G2OS6DTtmoebbQGnL7Ul+YsTDdsycE9CH+0R/u2/I/pU7qofVqPNEn+tvdb4ZzdA52P/BdH56N6p9cu1+NrTyq+KFmodV9YNJ/m16PZIv73ckWcucW2PE67aRhZxva7XWPpXeP3C+tKrO6T9svm1iyHXbyCLNtyenN3eek2R58MOa0uu2lyQ/23/sLf0/75g5J6APd2t/e9U6nxp3ZnrN7JeSfHjWA9vBXtDfzn3i7xC/199evc6+FyXZm+S2ed9pvgM9v79dmHlYVT+S3odw/El6IfNzQ55qzg3YwnXbyMLNtw383f52pZuX+TaatddtI4s03x5J8h+GfP1x/zl/0P/zSvnLzplz02iufrJ8xQcVjXPNvjTJ09Z5/EvS63zTkvzovMfZha+M9kFFf5Md8IEKHbx2lyU5bZ3Hr0jv0+NakhfO+79jRtfqJ/r/vf99vffmmueac+NdN/Ot9997SZJnrPP4rjz+gTsHBx4338a7bubb5tf0hgz/oKIdMeeqPzDWUVUXpvc/7OlJ3ptey53L0rtL+vb03gD3z2+E3VNVNyR5bXq/gbg7vS4uFyb5pvTeAO9L8q2ttUfnNcZ5qqqXJHlJ/4/PSPL16a10fLD/2H2ttR9e8/xfTe+H7i+n95HE35Jeq6hfTfIdbUHexFu5dv1WY1+a5PeT/FV//1fk8R64P9Fa+5fTHvO8VdV3J3lXeitvb8v6dZWHW2vvGjjmJVnwObfV62a+9fTLgf51ev2k70qvN/e5Sb42vZsdP5vkytbaXw4c85KYbz+YLVw3821z/SzyuiTf21r7uTX7XpKdMOfm/S+Ern8leVZ6bQPvSfJokk+ld7PQhisqi/qV3g+U/5xep4O/Te9DPf4mye+k1z+45j3GOV+fG9L7F/qwr8PrHHMgvX/YfD69sqo/T/LqJKfM+7+nq9cuyfck+a30Pgn4C+mtlnw6ya8k+Zp5/7d06Jq1JL9vzm3vuplvJ67Dl6X3ydt/kuS+9Gp5H0zyR/1ruu7fm+bb1q6b+TbSNV15D798yP7Ozzkr6AAA0CFuEgUAgA4R0AEAoEMEdAAA6BABHQAAOkRABwCADhHQAQCgQwR0AADoEAEdAAA6REAHAIAOEdABAKBDBHQAAOgQAR0AADpEQAcAgA4R0AEAoEMEdAAA6BABHQAAOkRABwCADvn/AeWnQMJJPg8sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance = jnp.exp(-jnp.array(ans[\"loss\"])) / jnp.exp(-optimal_loss)\n",
    "plt.plot(dimensions, performance, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5c657-b57e-4af9-9b5f-d17ac68ad38d",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ffeb20-b9aa-4431-9de3-deec9acd8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import flax.linen as nn\n",
    "from typing import Sequence\n",
    "from jax.nn import one_hot\n",
    "from flax.training import train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf459a5-1c67-4fb8-9825-64acde15c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9054e966-d19e-4884-8137-a8eebd708cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot be used with @jax.jit due to the\n",
    "# variable number of features, unless we\n",
    "# use static args\n",
    "class MLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for feat in self.features[:-1]:\n",
    "            x = nn.relu(nn.Dense(feat)(x))\n",
    "        x = nn.Dense(self.features[-1])(x)\n",
    "        return nn.log_softmax(x)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.relu(nn.Dense(784)(x))\n",
    "        x = nn.relu(nn.Dense(200)(x))\n",
    "        x = nn.relu(nn.Dense(200)(x))\n",
    "        x = nn.Dense(10)(x)\n",
    "        return nn.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bab4890-12f4-49c8-b8c5-054d1d6a96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    \"\"\"\n",
    "    Load MNIST train and test datasets into memory\n",
    "    \"\"\"\n",
    "    ds_builder = tfds.builder(\"mnist\")\n",
    "    ds_builder.download_and_prepare()\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split=\"train\", batch_size=-1))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split=\"test\", batch_size=-1))\n",
    "    train_ds[\"image\"] = jnp.float32(train_ds[\"image\"]) / 255.0\n",
    "    test_ds[\"image\"] = jnp.float32(test_ds[\"image\"]) / 255.0\n",
    "    return train_ds, test_ds\n",
    "\n",
    "\n",
    "def cross_entropy_loss(*, logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))\n",
    "\n",
    "\n",
    "def compute_metrics(*, logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "        \"loss\": loss,\n",
    "        \"accuracy\": accuracy,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    mlp = MLP()\n",
    "    params = mlp.init(rng, jnp.ones((1, 28**2)))[\"params\"]\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(apply_fn=mlp.apply, params=params, tx=tx)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits = MLP().apply({\"params\": params}, batch[\"image\"])\n",
    "        loss = cross_entropy_loss(logits=logits, labels=batch[\"label\"])\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=batch[\"label\"])\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afffc5a-1d8b-41a3-b8fb-f6609d648067",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee34ee81-51bd-4980-9730-ed5d24edd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = get_datasets()\n",
    "train_ds[\"image\"] = train_ds[\"image\"].reshape(-1, 28**2)\n",
    "test_ds[\"image\"] = test_ds[\"image\"].reshape(-1, 28**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b155d69-8006-4063-9016-3b0bb3160ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(jnp.unique(train_ds[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb28b95-f1d4-47fe-866f-59f5604af582",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c1ef8-ae68-464d-9e49-d6b9bd6a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "key = random.PRNGKey(314)\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "state = create_train_state(key, learning_rate, momentum)\n",
    "\n",
    "n_epochs = 100\n",
    "for e in range(n_epochs):\n",
    "    state, metrics = train_step(state, train_ds)\n",
    "    epoch_metrics = jax.device_get(metrics)\n",
    "    epoch_accuracy = epoch_metrics[\"accuracy\"]\n",
    "    epoch_loss = epoch_metrics[\"loss\"]\n",
    "    end = \"\\n\" if e % 9 == 0 else \"\\r\"\n",
    "    metric_str = f\"epoch: {e+1:03} || acc: {epoch_accuracy:0.2%} || loss:{epoch_loss:0.2f}\"\n",
    "    print(metric_str, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fad72-6471-4939-939d-b82872c076f4",
   "metadata": {},
   "source": [
    "## Subpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb1e2f4c-dcc3-493e-a1ac-a27bfa0caf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d67683a-0163-4713-9ea9-ae644c36713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb32cba-d081-4aa8-9270-666b3ac03050",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_utils_url = \"https://raw.githubusercontent.com/ganguli-lab/degrees-of-freedom/main/training_utils.py\"\n",
    "filename = \"../scripts/training_utils.py\"\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    print(f\"Writing to {filename}\")\n",
    "    r = requests.get(training_utils_url)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96563e51-fb38-4f2b-98ac-25fced2c568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../scripts/\")\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f181231c-ec53-47a8-96d8-8bd1db304108",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def cross_entropy_loss(logits, label):\n",
    "    return -logits[label]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def normal_loss(params, batch):\n",
    "    logits = MLP().apply({\"params\": params}, batch[\"image\"])\n",
    "    logits = jax.nn.log_softmax(logits)\n",
    "\n",
    "    loss = jnp.mean(cross_entropy_loss(logits, batch[\"label\"]))\n",
    "    return loss\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def normal_accuracy(params, batch):\n",
    "    logits = MLP().apply({\"params\": params}, batch[\"image\"])\n",
    "    logits = jax.nn.log_softmax(logits)\n",
    "    return jnp.mean(jnp.argmax(logits, -1) == batch[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "321d905a-2fb2-4116-b2d2-07f9484649dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(314)\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "state = create_train_state(key, learning_rate, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f04cc2d-76ea-425d-9b3c-c2a0bfa69cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = state.params\n",
    "leaves0, treedef = jax.tree_flatten(init_params)\n",
    "vec0, shapes_list = training_utils.flatten_leaves(leaves0)\n",
    "\n",
    "# To-do: add explicit dependence on , vec0, treedef, ahd shapes_list\n",
    "def projected_loss(theta_subspace, batch):\n",
    "    \"\"\"\n",
    "    1. Project theta_subspace ∈ R^d => theta ∈ R^D\n",
    "    2. Compute loss of the model w.r.t. theta_subspace\n",
    "    \"\"\"\n",
    "    projected_subspace_params = training_utils.theta_to_paramstree(theta_subspace, M, vec0, treedef, shapes_list)\n",
    "    return normal_loss(projected_subspace_params, batch)\n",
    "\n",
    "\n",
    "loss_grad_wrt_theta = jax.grad(projected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdaea1ae-1f67-48cd-a149-e202f4c85029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem dimension D=814,650\n"
     ]
    }
   ],
   "source": [
    "flat_params, *_ = jax.tree_flatten(init_params)\n",
    "D = sum([np.prod(params.shape) for params in flat_params])\n",
    "print(f\"Problem dimension D={D:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "009733fe-993e-4c6a-86ee-f2899ba821e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 814650)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(314)\n",
    "d = 750\n",
    "M = jnp.array(training_utils.generate_projection(d, D))\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2543bba1-74ec-40bf-90df-7056692c7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def adam_update(grads, params, mass, velocity, hyperparams):\n",
    "\n",
    "    mass = hyperparams[\"beta_1\"] * mass + (1.0 - hyperparams[\"beta_1\"]) * grads\n",
    "    velocity = hyperparams[\"beta_2\"] * velocity + (1.0 - hyperparams[\"beta_2\"]) * (grads**2.0)\n",
    "    # Bias correction\n",
    "    hat_mass = mass / (1 - hyperparams[\"beta_1\"])\n",
    "    hat_velocity = velocity / (1 - hyperparams[\"beta_2\"])\n",
    "    # Update\n",
    "    params = params - hyperparams[\"lr\"] / (jnp.sqrt(hat_velocity) + hyperparams[\"epsilon\"]) * hat_mass\n",
    "\n",
    "    return params, mass, velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8cde37c-bfdd-4211-a640-b1cb59200982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing subpace d=750\n",
      "epoch: 001 || acc: 17.38% || loss:2.28 || val acc: 17.81%\n",
      "epoch: 101 || acc: 88.71% || loss:0.37 || val acc: 89.14%\n",
      "epoch: 201 || acc: 90.07% || loss:0.32 || val acc: 90.25%\n",
      "epoch: 300 || acc: 90.68% || loss:0.31 || val acc: 90.76%\n",
      "CPU times: user 39.3 s, sys: 10.3 s, total: 49.6 s\n",
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_epochs = 300\n",
    "hyperparams = {\"lr\": 1e-1, \"beta_1\": 0.9, \"beta_2\": 0.999, \"epsilon\": 1e-7}\n",
    "\n",
    "theta = jnp.zeros((1, d))\n",
    "mass = jnp.zeros((1, d))\n",
    "velocity = jnp.zeros((1, d))\n",
    "\n",
    "print(f\"Testing subpace {d=}\")\n",
    "for e in range(n_epochs):\n",
    "    grads = loss_grad_wrt_theta(theta, train_ds)\n",
    "    theta, mass, velocity = adam_update(grads, theta, mass, velocity, hyperparams)\n",
    "    params_now = training_utils.theta_to_paramstree(theta, M, vec0, treedef, shapes_list)\n",
    "    epoch_loss = normal_loss(params_now, train_ds)\n",
    "    epoch_accuracy = normal_accuracy(params_now, train_ds)\n",
    "    if e % 100 == 0 or e == n_epochs - 1:\n",
    "        end = \"\\n\"\n",
    "        epoch_val_accuracy = normal_accuracy(params_now, test_ds)\n",
    "        val_str = f\" || val acc: {epoch_val_accuracy:0.2%}\"\n",
    "    else:\n",
    "        end = \"\\r\"\n",
    "        val_str = \"\"\n",
    "\n",
    "    metric_str = f\"epoch: {e+1:03} || acc: {epoch_accuracy:0.2%} || loss:{epoch_loss:0.2f}\"\n",
    "    metric_str += val_str\n",
    "    print(metric_str, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e75a3f98-76c9-496b-8af3-c48ff22bf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300\n",
    "\n",
    "hyperparams = {\"lr\": 1e-1, \"beta_1\": 0.9, \"beta_2\": 0.999, \"epsilon\": 1e-7}\n",
    "\n",
    "\n",
    "def get_metric_str(epoch, params, test_ds, n_epochs, epoch_accuracy, epoch_loss):\n",
    "    if epoch % 100 == 0 or epoch == n_epochs - 1:\n",
    "        end = \"\\n\"\n",
    "        epoch_val_accuracy = normal_accuracy(params, test_ds)\n",
    "        val_str = f\" || val acc: {epoch_val_accuracy:0.2%}\"\n",
    "    else:\n",
    "        end = \"\\r\"\n",
    "        val_str = \"\"\n",
    "\n",
    "    metric_str = f\"epoch: {epoch+1:03} || acc: {epoch_accuracy:0.2%} || loss:{epoch_loss:0.2f}\"\n",
    "    metric_str += val_str\n",
    "    return metric_str, end\n",
    "\n",
    "\n",
    "def train_mlp_subspace(d, D, n_epochs, hyperparams, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    M = jnp.array(training_utils.generate_projection(d, D))\n",
    "    theta, mass, velocity = jnp.zeros((3, 1, d))\n",
    "\n",
    "    @jax.jit\n",
    "    def projected_loss(theta_subspace, batch):\n",
    "        \"\"\"\n",
    "        1. Project theta_subspace ∈ R^d => theta ∈ R^D\n",
    "        2. Compute loss of the model w.r.t. theta_subspace\n",
    "        \"\"\"\n",
    "        projected_subspace_params = training_utils.theta_to_paramstree(theta_subspace, M, vec0, treedef, shapes_list)\n",
    "        return normal_loss(projected_subspace_params, batch)\n",
    "\n",
    "    loss_grad_wrt_theta = jax.grad(projected_loss)\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        grads = loss_grad_wrt_theta(theta, train_ds)\n",
    "        theta, mass, velocity = adam_update(grads, theta, mass, velocity, hyperparams)\n",
    "        params_now = training_utils.theta_to_paramstree(theta, M, vec0, treedef, shapes_list)\n",
    "\n",
    "        epoch_loss = normal_loss(params_now, train_ds)\n",
    "        epoch_accuracy = normal_accuracy(params_now, train_ds)\n",
    "        metric_str, end = get_metric_str(e, params_now, test_ds, n_epochs, epoch_accuracy, epoch_loss)\n",
    "\n",
    "        print(metric_str, end=end)\n",
    "\n",
    "    return params_now, (epoch_loss, epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6f6b691-db28-48aa-a79d-f3703601c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 750\n",
    "# params, _ = train_mlp_subspace(d, D, n_epochs, hyperparams, 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d25faaa9-9d49-4695-80b3-6ac77662553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 || acc: 17.38% || loss:2.28 || val acc: 17.81%\n",
      "epoch: 101 || acc: 88.71% || loss:0.37 || val acc: 89.14%\n",
      "epoch: 201 || acc: 90.07% || loss:0.32 || val acc: 90.25%\n",
      "epoch: 300 || acc: 90.68% || loss:0.31 || val acc: 90.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1 s\n",
       "\n",
       "Total time: 68.5034 s\n",
       "File: <ipython-input-36-6dbbc81c22e4>\n",
       "Function: train_mlp_subspace at line 24\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    24                                           def train_mlp_subspace(d, D, n_epochs, hyperparams, seed=None):\n",
       "    25         1          0.0      0.0      0.0      np.random.seed(seed)\n",
       "    26         1         18.8     18.8     27.4      M = jnp.array(training_utils.generate_projection(d, D))\n",
       "    27         1          0.0      0.0      0.0      theta, mass, velocity = jnp.zeros((3, 1, d))\n",
       "    28                                               \n",
       "    29         1          0.0      0.0      0.0      def projected_loss(theta_subspace, batch):\n",
       "    30                                                   \"\"\"\n",
       "    31                                                   1. Project theta_subspace ∈ R^d => theta ∈ R^D\n",
       "    32                                                   2. Compute loss of the model w.r.t. theta_subspace\n",
       "    33                                                   \"\"\"\n",
       "    34                                                   projected_subspace_params = training_utils.theta_to_paramstree(theta_subspace, M, vec0, treedef, shapes_list)\n",
       "    35                                                   return normal_loss(projected_subspace_params, batch)\n",
       "    36                                           \n",
       "    37         1          0.0      0.0      0.0      loss_grad_wrt_theta = jax.grad(projected_loss)\n",
       "    38                                               \n",
       "    39       301          0.0      0.0      0.0      for e in range(n_epochs):\n",
       "    40       300         31.4      0.1     45.9          grads = loss_grad_wrt_theta(theta, train_ds)\n",
       "    41       300          0.1      0.0      0.1          theta, mass, velocity = adam_update(grads, theta, mass, velocity, hyperparams)\n",
       "    42       300         15.5      0.1     22.7          params_now = training_utils.theta_to_paramstree(theta, M, vec0, treedef, shapes_list)\n",
       "    43                                                   \n",
       "    44       300          0.1      0.0      0.2          epoch_loss = normal_loss(params_now, train_ds)\n",
       "    45       300          0.1      0.0      0.1          epoch_accuracy = normal_accuracy(params_now, train_ds)\n",
       "    46       300          2.4      0.0      3.6          metric_str, end = get_metric_str(e, params_now, test_ds, n_epochs, epoch_accuracy, epoch_loss)\n",
       "    47                                                   \n",
       "    48       300          0.0      0.0      0.1          print(metric_str, end=end)\n",
       "    49                                                   \n",
       "    50         1          0.0      0.0      0.0      return params_now, (epoch_loss, epoch_accuracy)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -u 1 -f train_mlp_subspace params, _ = train_mlp_subspace(d, D, n_epochs, hyperparams, 314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d69b45-9bbd-444e-9df7-318de190f928",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6f6cd26-a6b1-4dfa-b9fb-a2cd6e86c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing subpace d=2\n",
      "epoch: 001 || acc: 10.19% || loss:2.31 || val acc: 10.65%\n",
      "epoch: 101 || acc: 10.15% || loss:2.31 || val acc: 10.43%\n",
      "epoch: 201 || acc: 10.18% || loss:2.31 || val acc: 10.42%\n",
      "epoch: 300 || acc: 10.15% || loss:2.31 || val acc: 10.44%\n",
      "Total run: 33.31s\n",
      "\n",
      "\n",
      "Testing subpace d=10\n",
      "epoch: 001 || acc: 10.27% || loss:2.31 || val acc: 10.82%\n",
      "epoch: 101 || acc: 19.63% || loss:2.23 || val acc: 20.17%\n",
      "epoch: 201 || acc: 23.62% || loss:2.20 || val acc: 23.81%\n",
      "epoch: 300 || acc: 24.58% || loss:2.19 || val acc: 24.62%\n",
      "Total run: 31.10s\n",
      "\n",
      "\n",
      "Testing subpace d=30\n",
      "epoch: 001 || acc: 10.45% || loss:2.31 || val acc: 10.81%\n",
      "epoch: 101 || acc: 33.25% || loss:1.96 || val acc: 32.72%\n",
      "epoch: 201 || acc: 35.33% || loss:1.88 || val acc: 35.99%\n",
      "epoch: 300 || acc: 35.52% || loss:1.87 || val acc: 35.66%\n",
      "Total run: 31.74s\n",
      "\n",
      "\n",
      "Testing subpace d=50\n",
      "epoch: 001 || acc: 10.72% || loss:2.31 || val acc: 11.24%\n",
      "epoch: 101 || acc: 39.07% || loss:1.78 || val acc: 40.18%\n",
      "epoch: 201 || acc: 42.94% || loss:1.69 || val acc: 44.04%\n",
      "epoch: 300 || acc: 43.58% || loss:1.66 || val acc: 45.22%\n",
      "Total run: 31.73s\n",
      "\n",
      "\n",
      "Testing subpace d=70\n",
      "epoch: 001 || acc: 10.74% || loss:2.30 || val acc: 11.21%\n",
      "epoch: 101 || acc: 46.04% || loss:1.65 || val acc: 47.67%\n",
      "epoch: 201 || acc: 51.50% || loss:1.51 || val acc: 52.52%\n",
      "epoch: 300 || acc: 52.86% || loss:1.47 || val acc: 54.55%\n",
      "Total run: 32.44s\n",
      "\n",
      "\n",
      "Testing subpace d=90\n",
      "epoch: 001 || acc: 10.89% || loss:2.30 || val acc: 11.46%\n",
      "epoch: 101 || acc: 51.02% || loss:1.47 || val acc: 52.25%\n",
      "epoch: 201 || acc: 55.71% || loss:1.37 || val acc: 57.47%\n",
      "epoch: 300 || acc: 57.31% || loss:1.32 || val acc: 58.84%\n",
      "Total run: 33.46s\n",
      "\n",
      "\n",
      "Testing subpace d=110\n",
      "epoch: 001 || acc: 11.12% || loss:2.30 || val acc: 11.65%\n",
      "epoch: 101 || acc: 58.69% || loss:1.27 || val acc: 60.65%\n",
      "epoch: 201 || acc: 63.22% || loss:1.14 || val acc: 64.14%\n",
      "epoch: 300 || acc: 63.80% || loss:1.13 || val acc: 64.86%\n",
      "Total run: 33.73s\n",
      "\n",
      "\n",
      "Testing subpace d=130\n",
      "epoch: 001 || acc: 11.34% || loss:2.30 || val acc: 11.76%\n",
      "epoch: 101 || acc: 62.02% || loss:1.19 || val acc: 63.17%\n",
      "epoch: 201 || acc: 65.67% || loss:1.06 || val acc: 66.63%\n",
      "epoch: 300 || acc: 67.56% || loss:1.00 || val acc: 69.07%\n",
      "Total run: 33.52s\n",
      "\n",
      "\n",
      "Testing subpace d=150\n",
      "epoch: 001 || acc: 11.84% || loss:2.30 || val acc: 12.32%\n",
      "epoch: 101 || acc: 65.52% || loss:1.07 || val acc: 67.00%\n",
      "epoch: 201 || acc: 69.59% || loss:0.94 || val acc: 70.26%\n",
      "epoch: 300 || acc: 70.75% || loss:0.91 || val acc: 71.66%\n",
      "Total run: 35.02s\n",
      "\n",
      "\n",
      "Testing subpace d=170\n",
      "epoch: 001 || acc: 11.48% || loss:2.30 || val acc: 11.86%\n",
      "epoch: 101 || acc: 68.56% || loss:1.01 || val acc: 69.41%\n",
      "epoch: 201 || acc: 71.58% || loss:0.90 || val acc: 71.79%\n",
      "epoch: 300 || acc: 73.48% || loss:0.84 || val acc: 74.32%\n",
      "Total run: 36.18s\n",
      "\n",
      "\n",
      "Testing subpace d=190\n",
      "epoch: 001 || acc: 11.51% || loss:2.30 || val acc: 11.92%\n",
      "epoch: 101 || acc: 69.63% || loss:0.93 || val acc: 70.96%\n",
      "epoch: 201 || acc: 73.42% || loss:0.82 || val acc: 74.36%\n",
      "epoch: 300 || acc: 74.38% || loss:0.79 || val acc: 74.96%\n",
      "Total run: 37.35s\n",
      "\n",
      "\n",
      "Testing subpace d=210\n",
      "epoch: 001 || acc: 11.83% || loss:2.30 || val acc: 12.44%\n",
      "epoch: 101 || acc: 71.60% || loss:0.88 || val acc: 72.81%\n",
      "epoch: 201 || acc: 74.12% || loss:0.81 || val acc: 75.16%\n",
      "epoch: 300 || acc: 74.77% || loss:0.79 || val acc: 76.03%\n",
      "Total run: 37.75s\n",
      "\n",
      "\n",
      "Testing subpace d=230\n",
      "epoch: 001 || acc: 11.94% || loss:2.30 || val acc: 12.63%\n",
      "epoch: 101 || acc: 75.22% || loss:0.77 || val acc: 76.42%\n",
      "epoch: 201 || acc: 78.42% || loss:0.68 || val acc: 79.55%\n",
      "epoch: 300 || acc: 78.87% || loss:0.67 || val acc: 79.95%\n",
      "Total run: 38.53s\n",
      "\n",
      "\n",
      "Testing subpace d=250\n",
      "epoch: 001 || acc: 11.80% || loss:2.30 || val acc: 12.50%\n",
      "epoch: 101 || acc: 74.76% || loss:0.79 || val acc: 75.92%\n",
      "epoch: 201 || acc: 78.15% || loss:0.69 || val acc: 79.27%\n",
      "epoch: 300 || acc: 78.90% || loss:0.67 || val acc: 79.85%\n",
      "Total run: 40.08s\n",
      "\n",
      "\n",
      "Testing subpace d=270\n",
      "epoch: 001 || acc: 12.38% || loss:2.30 || val acc: 12.92%\n",
      "epoch: 101 || acc: 77.29% || loss:0.72 || val acc: 77.68%\n",
      "epoch: 201 || acc: 78.56% || loss:0.68 || val acc: 78.95%\n",
      "epoch: 300 || acc: 79.76% || loss:0.64 || val acc: 80.93%\n",
      "Total run: 39.93s\n",
      "\n",
      "\n",
      "Testing subpace d=290\n",
      "epoch: 001 || acc: 12.73% || loss:2.30 || val acc: 13.19%\n",
      "epoch: 101 || acc: 77.50% || loss:0.71 || val acc: 78.88%\n",
      "epoch: 201 || acc: 80.26% || loss:0.62 || val acc: 81.57%\n",
      "epoch: 300 || acc: 81.33% || loss:0.59 || val acc: 82.20%\n",
      "Total run: 42.19s\n",
      "\n",
      "\n",
      "Testing subpace d=310\n",
      "epoch: 001 || acc: 12.80% || loss:2.30 || val acc: 13.29%\n",
      "epoch: 101 || acc: 77.57% || loss:0.70 || val acc: 77.94%\n",
      "epoch: 201 || acc: 80.66% || loss:0.61 || val acc: 81.19%\n",
      "epoch: 300 || acc: 81.41% || loss:0.59 || val acc: 81.43%\n",
      "Total run: 41.76s\n",
      "\n",
      "\n",
      "Testing subpace d=330\n",
      "epoch: 001 || acc: 13.71% || loss:2.30 || val acc: 14.21%\n",
      "epoch: 101 || acc: 78.86% || loss:0.66 || val acc: 79.75%\n",
      "epoch: 201 || acc: 81.83% || loss:0.58 || val acc: 82.57%\n",
      "epoch: 300 || acc: 82.93% || loss:0.55 || val acc: 83.29%\n",
      "Total run: 42.41s\n",
      "\n",
      "\n",
      "Testing subpace d=350\n",
      "epoch: 001 || acc: 13.98% || loss:2.29 || val acc: 14.50%\n",
      "epoch: 101 || acc: 81.70% || loss:0.58 || val acc: 82.92%\n",
      "epoch: 201 || acc: 83.57% || loss:0.52 || val acc: 84.46%\n",
      "epoch: 300 || acc: 84.43% || loss:0.50 || val acc: 85.17%\n",
      "Total run: 43.55s\n",
      "\n",
      "\n",
      "Testing subpace d=370\n",
      "epoch: 001 || acc: 13.71% || loss:2.29 || val acc: 14.23%\n",
      "epoch: 101 || acc: 81.77% || loss:0.59 || val acc: 82.42%\n",
      "epoch: 201 || acc: 84.32% || loss:0.51 || val acc: 84.32%\n",
      "epoch: 300 || acc: 84.94% || loss:0.49 || val acc: 85.26%\n",
      "Total run: 44.78s\n",
      "\n",
      "\n",
      "Testing subpace d=390\n",
      "epoch: 001 || acc: 13.77% || loss:2.29 || val acc: 14.34%\n",
      "epoch: 101 || acc: 83.13% || loss:0.54 || val acc: 83.73%\n",
      "epoch: 201 || acc: 85.26% || loss:0.48 || val acc: 85.59%\n",
      "epoch: 300 || acc: 85.43% || loss:0.47 || val acc: 85.74%\n",
      "Total run: 45.56s\n",
      "\n",
      "\n",
      "Testing subpace d=410\n",
      "epoch: 001 || acc: 13.48% || loss:2.29 || val acc: 13.90%\n",
      "epoch: 101 || acc: 83.68% || loss:0.52 || val acc: 84.46%\n",
      "epoch: 201 || acc: 85.73% || loss:0.46 || val acc: 85.75%\n",
      "epoch: 300 || acc: 86.22% || loss:0.45 || val acc: 86.31%\n",
      "Total run: 45.78s\n",
      "\n",
      "\n",
      "Testing subpace d=430\n",
      "epoch: 001 || acc: 13.80% || loss:2.29 || val acc: 14.26%\n",
      "epoch: 101 || acc: 82.66% || loss:0.55 || val acc: 83.25%\n",
      "epoch: 201 || acc: 85.26% || loss:0.48 || val acc: 85.81%\n",
      "epoch: 300 || acc: 86.07% || loss:0.45 || val acc: 86.19%\n",
      "Total run: 46.71s\n",
      "\n",
      "\n",
      "Testing subpace d=450\n",
      "epoch: 001 || acc: 15.02% || loss:2.29 || val acc: 15.34%\n",
      "epoch: 101 || acc: 85.11% || loss:0.49 || val acc: 85.63%\n",
      "epoch: 201 || acc: 86.33% || loss:0.45 || val acc: 86.95%\n",
      "epoch: 300 || acc: 87.16% || loss:0.42 || val acc: 87.83%\n",
      "Total run: 47.32s\n",
      "\n",
      "\n",
      "Testing subpace d=470\n",
      "epoch: 001 || acc: 14.16% || loss:2.29 || val acc: 14.49%\n",
      "epoch: 101 || acc: 84.71% || loss:0.50 || val acc: 85.51%\n",
      "epoch: 201 || acc: 86.25% || loss:0.45 || val acc: 86.67%\n",
      "epoch: 300 || acc: 86.91% || loss:0.43 || val acc: 87.15%\n",
      "Total run: 48.52s\n",
      "\n",
      "\n",
      "Testing subpace d=490\n",
      "epoch: 001 || acc: 15.12% || loss:2.29 || val acc: 15.52%\n",
      "epoch: 101 || acc: 85.46% || loss:0.47 || val acc: 85.66%\n",
      "epoch: 201 || acc: 86.89% || loss:0.42 || val acc: 87.00%\n",
      "epoch: 300 || acc: 87.71% || loss:0.40 || val acc: 87.95%\n",
      "Total run: 48.09s\n",
      "\n",
      "\n",
      "Testing subpace d=510\n",
      "epoch: 001 || acc: 14.64% || loss:2.29 || val acc: 14.99%\n",
      "epoch: 101 || acc: 85.56% || loss:0.47 || val acc: 85.71%\n",
      "epoch: 201 || acc: 86.92% || loss:0.42 || val acc: 86.81%\n",
      "epoch: 300 || acc: 87.57% || loss:0.40 || val acc: 87.54%\n",
      "Total run: 50.74s\n",
      "\n",
      "\n",
      "Testing subpace d=530\n",
      "epoch: 001 || acc: 14.65% || loss:2.29 || val acc: 14.98%\n",
      "epoch: 101 || acc: 85.81% || loss:0.46 || val acc: 86.42%\n",
      "epoch: 201 || acc: 87.56% || loss:0.41 || val acc: 88.17%\n",
      "epoch: 300 || acc: 88.08% || loss:0.39 || val acc: 88.67%\n",
      "Total run: 52.12s\n",
      "\n",
      "\n",
      "Testing subpace d=550\n",
      "epoch: 001 || acc: 15.45% || loss:2.29 || val acc: 15.91%\n",
      "epoch: 101 || acc: 87.25% || loss:0.42 || val acc: 87.70%\n",
      "epoch: 201 || acc: 88.34% || loss:0.38 || val acc: 88.49%\n",
      "epoch: 300 || acc: 88.80% || loss:0.37 || val acc: 88.57%\n",
      "Total run: 52.14s\n",
      "\n",
      "\n",
      "Testing subpace d=570\n",
      "epoch: 001 || acc: 16.11% || loss:2.29 || val acc: 16.37%\n",
      "epoch: 101 || acc: 87.05% || loss:0.42 || val acc: 87.42%\n",
      "epoch: 201 || acc: 88.37% || loss:0.38 || val acc: 88.45%\n",
      "epoch: 300 || acc: 88.77% || loss:0.36 || val acc: 88.62%\n",
      "Total run: 51.23s\n",
      "\n",
      "\n",
      "Testing subpace d=590\n",
      "epoch: 001 || acc: 16.93% || loss:2.29 || val acc: 17.17%\n",
      "epoch: 101 || acc: 86.73% || loss:0.43 || val acc: 87.34%\n",
      "epoch: 201 || acc: 88.03% || loss:0.40 || val acc: 88.16%\n",
      "epoch: 300 || acc: 88.45% || loss:0.38 || val acc: 88.18%\n",
      "Total run: 53.46s\n",
      "\n",
      "\n",
      "Testing subpace d=610\n",
      "epoch: 001 || acc: 15.29% || loss:2.29 || val acc: 15.60%\n",
      "epoch: 101 || acc: 87.79% || loss:0.40 || val acc: 88.05%\n",
      "epoch: 201 || acc: 88.94% || loss:0.36 || val acc: 88.89%\n",
      "epoch: 300 || acc: 89.36% || loss:0.35 || val acc: 89.34%\n",
      "Total run: 53.22s\n",
      "\n",
      "\n",
      "Testing subpace d=630\n",
      "epoch: 001 || acc: 16.60% || loss:2.28 || val acc: 17.18%\n",
      "epoch: 101 || acc: 87.56% || loss:0.41 || val acc: 87.95%\n",
      "epoch: 201 || acc: 89.00% || loss:0.36 || val acc: 89.14%\n",
      "epoch: 300 || acc: 89.70% || loss:0.34 || val acc: 89.61%\n",
      "Total run: 54.39s\n",
      "\n",
      "\n",
      "Testing subpace d=650\n",
      "epoch: 001 || acc: 17.06% || loss:2.28 || val acc: 17.45%\n",
      "epoch: 101 || acc: 88.15% || loss:0.39 || val acc: 88.63%\n",
      "epoch: 201 || acc: 89.39% || loss:0.35 || val acc: 89.46%\n",
      "epoch: 300 || acc: 89.95% || loss:0.33 || val acc: 89.70%\n",
      "Total run: 55.43s\n",
      "\n",
      "\n",
      "Testing subpace d=670\n",
      "epoch: 001 || acc: 17.44% || loss:2.28 || val acc: 17.68%\n",
      "epoch: 101 || acc: 88.67% || loss:0.38 || val acc: 88.33%\n",
      "epoch: 201 || acc: 89.75% || loss:0.34 || val acc: 89.17%\n",
      "epoch: 300 || acc: 90.05% || loss:0.33 || val acc: 89.49%\n",
      "Total run: 56.60s\n",
      "\n",
      "\n",
      "Testing subpace d=690\n",
      "epoch: 001 || acc: 15.64% || loss:2.28 || val acc: 16.31%\n",
      "epoch: 101 || acc: 89.12% || loss:0.36 || val acc: 89.43%\n",
      "epoch: 201 || acc: 90.07% || loss:0.33 || val acc: 89.99%\n",
      "epoch: 300 || acc: 90.43% || loss:0.32 || val acc: 90.11%\n",
      "Total run: 57.15s\n",
      "\n",
      "\n",
      "Testing subpace d=710\n",
      "epoch: 001 || acc: 17.95% || loss:2.28 || val acc: 18.38%\n",
      "epoch: 101 || acc: 88.78% || loss:0.37 || val acc: 89.40%\n",
      "epoch: 201 || acc: 90.20% || loss:0.32 || val acc: 90.31%\n",
      "epoch: 300 || acc: 90.65% || loss:0.31 || val acc: 90.87%\n",
      "Total run: 57.96s\n",
      "\n",
      "\n",
      "Testing subpace d=730\n",
      "epoch: 001 || acc: 17.47% || loss:2.28 || val acc: 17.97%\n",
      "epoch: 101 || acc: 88.69% || loss:0.37 || val acc: 88.55%\n",
      "epoch: 201 || acc: 89.96% || loss:0.33 || val acc: 89.45%\n",
      "epoch: 300 || acc: 90.46% || loss:0.32 || val acc: 90.28%\n",
      "Total run: 57.70s\n",
      "\n",
      "\n",
      "Testing subpace d=750\n",
      "epoch: 001 || acc: 16.31% || loss:2.28 || val acc: 16.86%\n",
      "epoch: 101 || acc: 89.07% || loss:0.36 || val acc: 89.09%\n",
      "epoch: 201 || acc: 90.31% || loss:0.32 || val acc: 90.18%\n",
      "epoch: 300 || acc: 90.60% || loss:0.31 || val acc: 90.56%\n",
      "Total run: 57.43s\n",
      "\n",
      "\n",
      "Testing subpace d=770\n",
      "epoch: 001 || acc: 18.23% || loss:2.28 || val acc: 18.69%\n",
      "epoch: 101 || acc: 89.22% || loss:0.36 || val acc: 89.22%\n",
      "epoch: 201 || acc: 90.35% || loss:0.32 || val acc: 90.02%\n",
      "epoch: 300 || acc: 90.85% || loss:0.30 || val acc: 90.43%\n",
      "Total run: 59.80s\n",
      "\n",
      "\n",
      "Testing subpace d=790\n",
      "epoch: 001 || acc: 17.22% || loss:2.28 || val acc: 17.73%\n",
      "epoch: 101 || acc: 89.39% || loss:0.35 || val acc: 89.69%\n",
      "epoch: 201 || acc: 90.66% || loss:0.31 || val acc: 90.55%\n",
      "epoch: 300 || acc: 91.06% || loss:0.30 || val acc: 90.82%\n",
      "Total run: 60.89s\n",
      "\n",
      "\n",
      "Testing subpace d=810\n",
      "epoch: 001 || acc: 17.10% || loss:2.28 || val acc: 17.44%\n",
      "epoch: 101 || acc: 89.52% || loss:0.34 || val acc: 89.88%\n",
      "epoch: 201 || acc: 90.76% || loss:0.30 || val acc: 91.00%\n",
      "epoch: 300 || acc: 91.37% || loss:0.28 || val acc: 91.25%\n",
      "Total run: 61.58s\n",
      "\n",
      "\n",
      "Testing subpace d=830\n",
      "epoch: 001 || acc: 18.17% || loss:2.28 || val acc: 18.55%\n",
      "epoch: 101 || acc: 89.90% || loss:0.33 || val acc: 89.93%\n",
      "epoch: 201 || acc: 91.02% || loss:0.30 || val acc: 91.08%\n",
      "epoch: 300 || acc: 91.53% || loss:0.28 || val acc: 91.11%\n",
      "Total run: 63.50s\n",
      "\n",
      "\n",
      "Testing subpace d=850\n",
      "epoch: 001 || acc: 19.32% || loss:2.28 || val acc: 19.55%\n",
      "epoch: 101 || acc: 89.87% || loss:0.34 || val acc: 89.98%\n",
      "epoch: 201 || acc: 91.11% || loss:0.30 || val acc: 90.91%\n",
      "epoch: 300 || acc: 91.50% || loss:0.28 || val acc: 91.05%\n",
      "Total run: 64.13s\n",
      "\n",
      "\n",
      "Testing subpace d=870\n",
      "epoch: 001 || acc: 17.98% || loss:2.28 || val acc: 18.37%\n",
      "epoch: 101 || acc: 90.29% || loss:0.32 || val acc: 90.53%\n",
      "epoch: 201 || acc: 91.47% || loss:0.28 || val acc: 91.51%\n",
      "epoch: 300 || acc: 92.05% || loss:0.26 || val acc: 92.02%\n",
      "Total run: 63.69s\n",
      "\n",
      "\n",
      "Testing subpace d=890\n",
      "epoch: 001 || acc: 19.16% || loss:2.28 || val acc: 19.35%\n",
      "epoch: 101 || acc: 90.37% || loss:0.32 || val acc: 90.32%\n",
      "epoch: 201 || acc: 91.41% || loss:0.28 || val acc: 91.20%\n",
      "epoch: 300 || acc: 91.90% || loss:0.27 || val acc: 91.43%\n",
      "Total run: 65.59s\n",
      "\n",
      "\n",
      "Testing subpace d=910\n",
      "epoch: 001 || acc: 18.46% || loss:2.28 || val acc: 18.57%\n",
      "epoch: 101 || acc: 90.16% || loss:0.32 || val acc: 90.29%\n",
      "epoch: 201 || acc: 91.66% || loss:0.28 || val acc: 91.42%\n",
      "epoch: 300 || acc: 92.08% || loss:0.26 || val acc: 91.62%\n",
      "Total run: 64.14s\n",
      "\n",
      "\n",
      "Testing subpace d=930\n",
      "epoch: 001 || acc: 18.35% || loss:2.27 || val acc: 18.47%\n",
      "epoch: 101 || acc: 90.95% || loss:0.30 || val acc: 90.45%\n",
      "epoch: 201 || acc: 91.97% || loss:0.27 || val acc: 91.12%\n",
      "epoch: 300 || acc: 92.25% || loss:0.26 || val acc: 91.35%\n",
      "Total run: 66.21s\n",
      "\n",
      "\n",
      "Testing subpace d=950\n",
      "epoch: 001 || acc: 20.64% || loss:2.27 || val acc: 20.85%\n",
      "epoch: 101 || acc: 90.96% || loss:0.30 || val acc: 90.94%\n",
      "epoch: 201 || acc: 91.89% || loss:0.27 || val acc: 92.02%\n",
      "epoch: 300 || acc: 92.28% || loss:0.26 || val acc: 91.70%\n",
      "Total run: 67.01s\n",
      "\n",
      "\n",
      "Testing subpace d=970\n",
      "epoch: 001 || acc: 20.07% || loss:2.27 || val acc: 20.24%\n",
      "epoch: 101 || acc: 91.06% || loss:0.30 || val acc: 91.21%\n",
      "epoch: 201 || acc: 92.09% || loss:0.26 || val acc: 91.74%\n",
      "epoch: 300 || acc: 92.44% || loss:0.25 || val acc: 91.98%\n",
      "Total run: 68.03s\n",
      "\n",
      "\n",
      "Testing subpace d=990\n",
      "epoch: 001 || acc: 20.38% || loss:2.27 || val acc: 20.80%\n",
      "epoch: 101 || acc: 90.60% || loss:0.31 || val acc: 90.60%\n",
      "epoch: 201 || acc: 91.87% || loss:0.27 || val acc: 91.59%\n",
      "epoch: 300 || acc: 92.25% || loss:0.25 || val acc: 91.70%\n",
      "Total run: 68.39s\n",
      "\n",
      "\n",
      "Testing subpace d=1010\n",
      "epoch: 001 || acc: 19.44% || loss:2.27 || val acc: 19.54%\n",
      "epoch: 101 || acc: 91.16% || loss:0.29 || val acc: 91.13%\n",
      "epoch: 201 || acc: 91.85% || loss:0.26 || val acc: 91.71%\n",
      "epoch: 300 || acc: 92.28% || loss:0.25 || val acc: 91.93%\n",
      "Total run: 69.97s\n",
      "\n",
      "\n",
      "Testing subpace d=1030\n",
      "epoch: 001 || acc: 19.57% || loss:2.27 || val acc: 19.79%\n",
      "epoch: 101 || acc: 91.22% || loss:0.29 || val acc: 91.34%\n",
      "epoch: 201 || acc: 92.30% || loss:0.25 || val acc: 91.60%\n",
      "epoch: 300 || acc: 92.72% || loss:0.24 || val acc: 92.01%\n",
      "Total run: 71.32s\n",
      "\n",
      "\n",
      "Testing subpace d=1050\n",
      "epoch: 001 || acc: 20.75% || loss:2.27 || val acc: 20.95%\n",
      "epoch: 101 || acc: 91.49% || loss:0.28 || val acc: 91.15%\n",
      "epoch: 201 || acc: 92.42% || loss:0.25 || val acc: 91.86%\n",
      "epoch: 300 || acc: 92.81% || loss:0.24 || val acc: 92.17%\n",
      "Total run: 71.16s\n",
      "\n",
      "\n",
      "Testing subpace d=1070\n",
      "epoch: 001 || acc: 20.33% || loss:2.27 || val acc: 20.81%\n",
      "epoch: 101 || acc: 91.09% || loss:0.30 || val acc: 90.86%\n",
      "epoch: 201 || acc: 92.34% || loss:0.26 || val acc: 91.58%\n",
      "epoch: 300 || acc: 92.81% || loss:0.24 || val acc: 92.21%\n",
      "Total run: 71.78s\n",
      "\n",
      "\n",
      "Testing subpace d=1090\n",
      "epoch: 001 || acc: 20.91% || loss:2.27 || val acc: 21.28%\n",
      "epoch: 101 || acc: 91.09% || loss:0.29 || val acc: 90.89%\n",
      "epoch: 201 || acc: 92.35% || loss:0.25 || val acc: 91.83%\n",
      "epoch: 300 || acc: 92.96% || loss:0.24 || val acc: 92.14%\n",
      "Total run: 73.15s\n",
      "\n",
      "\n",
      "Testing subpace d=1110\n",
      "epoch: 001 || acc: 20.46% || loss:2.27 || val acc: 20.86%\n",
      "epoch: 101 || acc: 91.82% || loss:0.27 || val acc: 92.11%\n",
      "epoch: 201 || acc: 92.67% || loss:0.24 || val acc: 92.26%\n",
      "epoch: 300 || acc: 93.07% || loss:0.23 || val acc: 92.21%\n",
      "Total run: 73.66s\n",
      "\n",
      "\n",
      "Testing subpace d=1130\n",
      "epoch: 001 || acc: 20.25% || loss:2.27 || val acc: 20.49%\n",
      "epoch: 101 || acc: 91.75% || loss:0.28 || val acc: 91.40%\n",
      "epoch: 201 || acc: 92.64% || loss:0.24 || val acc: 91.95%\n",
      "epoch: 300 || acc: 92.92% || loss:0.23 || val acc: 92.14%\n",
      "Total run: 73.39s\n",
      "\n",
      "\n",
      "Testing subpace d=1150\n",
      "epoch: 001 || acc: 20.96% || loss:2.27 || val acc: 21.35%\n",
      "epoch: 101 || acc: 91.47% || loss:0.28 || val acc: 91.62%\n",
      "epoch: 201 || acc: 92.62% || loss:0.24 || val acc: 92.55%\n",
      "epoch: 300 || acc: 93.22% || loss:0.23 || val acc: 92.67%\n",
      "Total run: 76.18s\n",
      "\n",
      "\n",
      "Testing subpace d=1170\n",
      "epoch: 001 || acc: 21.99% || loss:2.27 || val acc: 22.25%\n",
      "epoch: 101 || acc: 92.27% || loss:0.26 || val acc: 91.95%\n",
      "epoch: 201 || acc: 93.06% || loss:0.23 || val acc: 92.32%\n",
      "epoch: 300 || acc: 93.38% || loss:0.22 || val acc: 92.38%\n",
      "Total run: 75.09s\n",
      "\n",
      "\n",
      "Testing subpace d=1190\n",
      "epoch: 001 || acc: 20.63% || loss:2.27 || val acc: 21.11%\n",
      "epoch: 101 || acc: 91.75% || loss:0.27 || val acc: 91.45%\n",
      "epoch: 201 || acc: 92.77% || loss:0.24 || val acc: 92.48%\n",
      "epoch: 300 || acc: 93.27% || loss:0.22 || val acc: 92.69%\n",
      "Total run: 76.42s\n",
      "\n",
      "\n",
      "Testing subpace d=1210\n",
      "epoch: 001 || acc: 23.10% || loss:2.26 || val acc: 22.92%\n",
      "epoch: 101 || acc: 91.71% || loss:0.28 || val acc: 91.73%\n",
      "epoch: 201 || acc: 92.76% || loss:0.24 || val acc: 92.33%\n",
      "epoch: 300 || acc: 93.15% || loss:0.23 || val acc: 92.52%\n",
      "Total run: 76.27s\n",
      "\n",
      "\n",
      "Testing subpace d=1230\n",
      "epoch: 001 || acc: 20.85% || loss:2.26 || val acc: 21.40%\n",
      "epoch: 101 || acc: 92.30% || loss:0.26 || val acc: 92.33%\n",
      "epoch: 201 || acc: 93.31% || loss:0.22 || val acc: 93.00%\n",
      "epoch: 300 || acc: 93.70% || loss:0.21 || val acc: 93.16%\n",
      "Total run: 77.14s\n",
      "\n",
      "\n",
      "Testing subpace d=1250\n",
      "epoch: 001 || acc: 21.64% || loss:2.26 || val acc: 21.88%\n",
      "epoch: 101 || acc: 92.39% || loss:0.25 || val acc: 91.70%\n",
      "epoch: 201 || acc: 93.24% || loss:0.22 || val acc: 92.38%\n",
      "epoch: 300 || acc: 93.67% || loss:0.21 || val acc: 92.57%\n",
      "Total run: 82.84s\n",
      "\n",
      "\n",
      "Testing subpace d=1270\n",
      "epoch: 001 || acc: 21.76% || loss:2.26 || val acc: 22.35%\n",
      "epoch: 101 || acc: 92.36% || loss:0.26 || val acc: 91.34%\n",
      "epoch: 201 || acc: 93.17% || loss:0.22 || val acc: 92.27%\n",
      "epoch: 300 || acc: 93.63% || loss:0.21 || val acc: 92.28%\n",
      "Total run: 83.80s\n",
      "\n",
      "\n",
      "Testing subpace d=1290\n",
      "epoch: 001 || acc: 22.02% || loss:2.26 || val acc: 22.28%\n",
      "epoch: 101 || acc: 92.10% || loss:0.26 || val acc: 91.76%\n",
      "epoch: 201 || acc: 93.15% || loss:0.23 || val acc: 92.44%\n",
      "epoch: 300 || acc: 93.58% || loss:0.22 || val acc: 92.98%\n",
      "Total run: 84.45s\n"
     ]
    }
   ],
   "source": [
    "subspace_dims = [2] + list(range(10, 1300, 20))\n",
    "\n",
    "val_losses = []\n",
    "val_acc = []\n",
    "for d in subspace_dims:\n",
    "    print(f\"\\n\\nTesting subpace {d=}\")\n",
    "    init_time = time()\n",
    "    M = jnp.array(training_utils.generate_projection(d, D))\n",
    "\n",
    "    leaves0, treedef = jax.tree_flatten(init_params)\n",
    "    vec0, shapes_list = training_utils.flatten_leaves(leaves0)\n",
    "\n",
    "    def projected_loss(theta_subspace, batch):\n",
    "        \"\"\"\n",
    "        1. Project theta_subspace ∈ R^d => theta ∈ R^D.\n",
    "        2. Compute loss of the model w.r.t. theta_subspace\n",
    "        \"\"\"\n",
    "        projected_subspace_params = training_utils.theta_to_paramstree(theta_subspace, M, vec0, treedef, shapes_list)\n",
    "        return normal_loss(projected_subspace_params, batch)\n",
    "\n",
    "    loss_grad_wrt_theta = jax.grad(projected_loss)\n",
    "\n",
    "    theta = jnp.zeros((1, d))\n",
    "    lr = 1e-1\n",
    "    n_epochs = 300\n",
    "\n",
    "    beta_1 = 0.9\n",
    "    beta_2 = 0.999\n",
    "    epsilon = 1e-07\n",
    "    mass = jnp.zeros((1, d))\n",
    "    velocity = jnp.zeros((1, d))\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        grads = loss_grad_wrt_theta(theta, train_ds)\n",
    "\n",
    "        # *** Parameter update\n",
    "        mass = beta_1 * mass + (1.0 - beta_1) * grads\n",
    "        velocity = beta_2 * velocity + (1.0 - beta_2) * (grads**2.0)\n",
    "\n",
    "        # Bias correction\n",
    "        hat_mass = mass / (1.0 - beta_1)\n",
    "        hat_velocity = velocity / (1.0 - beta_2)\n",
    "\n",
    "        # Update\n",
    "        theta = theta - lr / (jnp.sqrt(hat_velocity) + epsilon) * hat_mass\n",
    "        # theta = theta - lr * grads\n",
    "        # *******************\n",
    "\n",
    "        params_now = training_utils.theta_to_paramstree(theta, M, vec0, treedef, shapes_list)\n",
    "        epoch_loss = normal_loss(params_now, train_ds)\n",
    "        epoch_accuracy = normal_accuracy(params_now, train_ds)\n",
    "        if e % 100 == 0 or e == n_epochs - 1:\n",
    "            end = \"\\n\"\n",
    "            epoch_val_accuracy = normal_accuracy(params_now, test_ds)\n",
    "            epoch_val_loss = normal_loss(params_now, test_ds)\n",
    "            val_str = f\" || val acc: {epoch_val_accuracy:0.2%}\"\n",
    "        else:\n",
    "            end = \"\\r\"\n",
    "            val_str = \"\"\n",
    "\n",
    "        metric_str = f\"epoch: {e+1:03} || acc: {epoch_accuracy:0.2%} || loss:{epoch_loss:0.2f}\"\n",
    "        metric_str += val_str\n",
    "        print(metric_str, end=end)\n",
    "\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_acc.append(epoch_val_accuracy)\n",
    "    end_time = time()\n",
    "    print(f\"Total run: {end_time - init_time:0.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a331b89-34e8-4ac1-8f66-eae0924ef342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Validation accuracy')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 216,
       "width": 444
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "plt.plot(subspace_dims[::3], val_acc[::3], marker=\"o\")\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "plt.axhline(y=0.9, c=\"tab:gray\", linestyle=\"--\")\n",
    "plt.xlabel(\"Subspace dim $d$\", fontsize=13)\n",
    "plt.ylabel(\"Validation accuracy\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc9901-659a-4a30-94e1-3fbc99298a62",
   "metadata": {},
   "source": [
    "## References \n",
    "1. https://github.com/ganguli-lab/degrees-of-freedom\n",
    "2. https://flax.readthedocs.io/en/latest/notebooks/annotated_mnist.html\n",
    "3. https://github.com/uber-research/intrinsic-dimension"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
