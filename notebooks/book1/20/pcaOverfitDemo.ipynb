{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 20.6, 20.7, 20.8\n",
    "\n",
    "# PCA train set and test set reconstruction error vs K\n",
    "# Reconstruction error on test set gets lower as K increased\n",
    "# Screeplot and fraction of variance explained\n",
    "# likelihood of PCA model shows “knee” or “elbow” in the curve\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from sklearn.decomposition import PCA\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.decomposition import PCA\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "try:\n",
    "    from tensorflow import keras\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq tensorflow\n",
    "    from tensorflow import keras\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)  # for some NaN values\n",
    "\n",
    "# Function to calculate log likelihood of PCA from eigenvalues\n",
    "# Implemented equations from the book:\n",
    "# \"Probabilistic Machine Learning: An Introduction\"\n",
    "\n",
    "\n",
    "def log_likelihood(evals):\n",
    "\n",
    "    Lmax = len(evals)\n",
    "    ll = np.arange(0.0, Lmax)\n",
    "\n",
    "    for L in range(Lmax):\n",
    "\n",
    "        group1 = evals[0 : L + 1]  # Divide Eigenvalues in two groups\n",
    "        group2 = evals[L + 1 : Lmax]\n",
    "\n",
    "        mu1 = np.mean(group1)\n",
    "        mu2 = np.mean(group2)\n",
    "\n",
    "        # eqn (20.30)\n",
    "        sigma = (np.sum((group1 - mu1) ** 2) + np.sum((group2 - mu2) ** 2)) / Lmax\n",
    "\n",
    "        ll_group1 = np.sum(multivariate_normal.logpdf(group1, mu1, sigma))\n",
    "        ll_group2 = np.sum(multivariate_normal.logpdf(group2, mu2, sigma))\n",
    "\n",
    "        ll[L] = ll_group1 + ll_group2  # eqn (20.31)\n",
    "\n",
    "    return ll\n",
    "\n",
    "\n",
    "# Standard mnist dataset\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images[train_labels == 3]  # select images of digit '3'\n",
    "\n",
    "n_images = 1000\n",
    "train_images = train_images[0:n_images, :, :]\n",
    "n_samples, n_rows, n_cols = train_images.shape\n",
    "X = np.reshape(train_images, (n_samples, n_rows * n_cols))\n",
    "\n",
    "X_train = X[0 : int(n_images / 2), :]  # 500 images in train set\n",
    "X_test = X[int(n_images / 2) :, :]  # 500 images in test set\n",
    "\n",
    "# Reconstruction error on MNIST vs number of latent dimensions used by PCA\n",
    "\n",
    "X_rank = np.linalg.matrix_rank(X_train)\n",
    "K_linspace = np.linspace(1, 0.75 * X_rank, 10, dtype=int)\n",
    "Ks = np.unique(np.append([1, 5, 10, 20], K_linspace))\n",
    "\n",
    "RMSE_train = np.arange(len(Ks))\n",
    "RMSE_test = np.arange(len(Ks))\n",
    "\n",
    "for index, K in enumerate(Ks):\n",
    "    pca = PCA(n_components=K)\n",
    "\n",
    "    Xtrain_transformed = pca.fit_transform(X_train)\n",
    "    Xtrain_proj = pca.inverse_transform(Xtrain_transformed)\n",
    "    RMSE_train[index] = mean_squared_error(X_train, Xtrain_proj, squared=False)\n",
    "\n",
    "    Xtest_transformed = pca.transform(X_test)\n",
    "    Xtest_proj = pca.inverse_transform(Xtest_transformed)\n",
    "    RMSE_test[index] = mean_squared_error(X_test, Xtest_proj, squared=False)\n",
    "\n",
    "# profile log likelihood for PCA\n",
    "\n",
    "n_samples, n_features = X_train.shape\n",
    "Kmax = min(n_samples, n_features)\n",
    "\n",
    "pca = PCA(n_components=Kmax)\n",
    "X_transformed = pca.fit_transform(X_train)\n",
    "evals = pca.explained_variance_  # eigenvalues in descending order\n",
    "\n",
    "ll = log_likelihood(evals)\n",
    "\n",
    "# Fraction of variance explained\n",
    "\n",
    "fraction_var = np.cumsum(evals[0:50] / np.sum(evals))\n",
    "\n",
    "# Figure 20.6(a) train set reconstruction error\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = Ks\n",
    "ys = RMSE_train\n",
    "plt.title(\"train set reconstruction error\")\n",
    "plt.xlabel(\"num PCs\")\n",
    "plt.ylabel(\"rmse\")\n",
    "ax.plot(xs, ys, marker=\"o\")\n",
    "plt.show()\n",
    "\n",
    "# Figure 20.6(b) test set reconstruction error\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = Ks\n",
    "ys = RMSE_test\n",
    "plt.title(\"test set reconstruction error\")\n",
    "plt.xlabel(\"num PCs\")\n",
    "plt.ylabel(\"rmse\")\n",
    "ax.plot(xs, ys, marker=\"o\")\n",
    "plt.show()\n",
    "\n",
    "# Figure 20.7(a) Scree plot for training set\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.arange(1, 51)\n",
    "ys = evals[0:50]\n",
    "plt.title(\"screeplot\")\n",
    "plt.xlabel(\"num PCs\")\n",
    "plt.ylabel(\"eigenvalues\")\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "ax.plot(xs, ys)\n",
    "plt.show()\n",
    "\n",
    "# Figure 20.7(b) Fraction of variance explained\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.arange(1, 51)\n",
    "ys = fraction_var\n",
    "plt.xlabel(\"num PCs\")\n",
    "plt.ylabel(\"proportion of variance explained\")\n",
    "ax.plot(xs, ys)\n",
    "plt.show()\n",
    "\n",
    "# Figure 20.8 Profile likelihood corresponding to PCA model\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.arange(1, 51)\n",
    "ys = ll[0:50]\n",
    "plt.xlabel(\"num PCs\")\n",
    "plt.ylabel(\"profile log likelihood\")\n",
    "\n",
    "ax.plot(xs, ys)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
