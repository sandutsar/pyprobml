{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321c3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from jax import vmap\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cf3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryFA:\n",
    "    def __init__(self, input_dim, latent, max_iter, conv_tol=1e-4, compute_ll=True):\n",
    "        self.W = 0.1 * np.random.randn(latent, input_dim)  # 2x16\n",
    "        self.b = 0.01 * np.random.randn(input_dim, 1)  # 16x1\n",
    "        self.mu_prior = np.zeros((latent, 1))  # 2x1\n",
    "        self.sigma_prior = np.eye(latent)  # 2x2\n",
    "        self.input_dim = input_dim\n",
    "        self.latent = latent\n",
    "        self.max_iter = max_iter\n",
    "        self.compute_ll = compute_ll\n",
    "        if compute_ll:\n",
    "            self.ll_hist = np.zeros((max_iter + 1, 1))  # 51x1\n",
    "\n",
    "    def variational_em(self, data):\n",
    "        ll_hist = np.zeros((self.max_iter + 1, 1))\n",
    "        i = 0\n",
    "        while i < 3:\n",
    "            S1, S2, ll = self.estep(data)\n",
    "            ll_hist[i, 0] = ll\n",
    "            self.mstep(S1, S2)\n",
    "            if i != 0:\n",
    "                delta_fval = abs(ll_hist[i] - ll_hist[i - 1])\n",
    "                avg_fval = (abs(ll_hist[i]) + abs(ll_hist[i - 1]) + np.finfo(float).eps) / 2\n",
    "                if (delta_fval / avg_fval) < conv_tol:\n",
    "                    break\n",
    "            i += 1\n",
    "        return ll_hist[:i]\n",
    "\n",
    "    def estep(self, data):\n",
    "        S1 = np.zeros((self.latent + 1, self.input_dim))  # 3x16\n",
    "        S2 = np.zeros((self.latent + 1, self.latent + 1, self.input_dim))  # 3x3x16\n",
    "        W, b, mu_prior = self.W, self.b, self.mu_prior\n",
    "        ll = 0\n",
    "        for i in range(data.T.shape[1]):\n",
    "            mu_post, sigma_post, logZ, lambd = self.compute_latent_posterior_statistics(data.T[:, i], max_iter=3)\n",
    "            ll += logZ\n",
    "            EZZ = np.zeros((self.latent + 1, self.latent + 1))\n",
    "            EZZ[: self.latent, : self.latent] = sigma_post + np.outer(mu_post, mu_post)\n",
    "            EZZ[self.latent, : self.latent] = mu_post.T\n",
    "            EZZ[: self.latent, self.latent] = np.squeeze(np.asarray(mu_post))\n",
    "            EZZ[self.latent, self.latent] = 1\n",
    "            EZ = np.append(mu_post, np.ones((1, 1)))\n",
    "            for j in range(self.input_dim):\n",
    "                S1[:, j] = S1[:, j] + (data.T[j, i] - 0.5) * EZ\n",
    "                S2[:, :, j] = S2[:, :, j] - 2 * lambd[j] * EZZ\n",
    "        return S1, S2, ll\n",
    "\n",
    "    def mstep(self, S1, S2):\n",
    "        for i in range(self.input_dim):\n",
    "            what = np.linalg.lstsq(S2[:, :, i], S1[:, i])[0]\n",
    "            self.W[:, i] = what[: self.latent]\n",
    "            self.b[i] = what[self.latent]\n",
    "\n",
    "    def compute_latent_posterior_statistics(self, y, output=[0, 0, 0, 0], max_iter=3):\n",
    "        W, b = np.copy(self.W), np.copy(self.b)\n",
    "        y = y.reshape((-1, 1))\n",
    "        # variational parameters\n",
    "        mu_prior = self.mu_prior\n",
    "        xi = (2 * y - 1) * (W.T @ mu_prior + b)\n",
    "        xi[xi == 0] = 0.01 * np.random.rand(np.count_nonzero(xi == 0))  # 16x1\n",
    "        sigma_inv, iter = np.linalg.inv(self.sigma_prior), 0\n",
    "        for iter in range(max_iter):\n",
    "            lambd = (0.5 - sigmoid(xi)) / (2 * xi)\n",
    "            tmp = W @ np.diagflat(lambd) @ W.T  # 2x2\n",
    "            sigma_post = np.linalg.inv(sigma_inv - (2 * tmp))\n",
    "            tmp = y - 0.5 + 2 * lambd * b\n",
    "            tmp2 = np.sum(W @ np.diagflat(tmp), axis=1).reshape((2, 1))\n",
    "            mu_post = sigma_post @ (sigma_inv @ mu_prior + tmp2)\n",
    "\n",
    "            tmp = np.diag(W.T @ (sigma_post + mu_post @ mu_post.T) @ W)\n",
    "            tmp = tmp.reshape((tmp.shape[0], 1))\n",
    "            tmp2 = 2 * (W @ np.diagflat(b)).T @ mu_post\n",
    "            xi = np.sqrt(tmp + tmp2 + b**2)\n",
    "            logZ = 0\n",
    "            if self.compute_ll:\n",
    "                lam = -lambd\n",
    "                A = np.diagflat(2 * lam)\n",
    "                invA = np.diagflat(1 / (2 * lam))\n",
    "                bb = -0.5 * np.ones((y.shape[0], 1))\n",
    "                c = -lam * xi**2 - 0.5 * xi + np.log(1 + np.exp(xi))\n",
    "                ytilde = invA @ (bb + y)\n",
    "                B = W.T\n",
    "                logconst1 = -0.5 * np.sum(np.log(lam / np.pi))\n",
    "                logconst2 = 0.5 * ytilde.T @ A @ ytilde - np.sum(c)\n",
    "                gauss = multivariate_normal.logpdf(\n",
    "                    np.squeeze(np.asarray(ytilde)),\n",
    "                    mean=np.squeeze(np.asarray(B @ mu_prior + b)),\n",
    "                    cov=(invA + B @ sigma_post @ B.T),\n",
    "                )\n",
    "                logZ = logconst1 + logconst2 + gauss\n",
    "                output = [mu_post, sigma_post, logZ, lambd]\n",
    "        return output\n",
    "\n",
    "    def predict_missing(self, y):\n",
    "        N, T = y.shape  # 150 x 16\n",
    "        prob_on = np.zeros(y.shape)  # 150 x 16\n",
    "        post_pred = np.zeros((N, T, 2))  # 150 x 16 x 2\n",
    "        L, p = self.W.shape  # 16 x 3\n",
    "        B = np.c_[np.copy(self.b), self.W.T]  # 16 x 3\n",
    "        for n in range(N):\n",
    "            mu_post, sigma_post, logZ, lambd = self.compute_latent_posterior_statistics(y[n, :].T, False)\n",
    "            mu1 = np.r_[np.ones((1, 1)), mu_post]\n",
    "            sigma1 = np.zeros((L + 1, L + 1))\n",
    "            sigma1[1:, 1:] = sigma_post\n",
    "            prob_on[n, :] = sigmoid_times_gauss(B, mu1, sigma1)\n",
    "\n",
    "        return prob_on\n",
    "\n",
    "    def infer_latent(self, y):\n",
    "        N, T = y.shape\n",
    "        W, b, mu_prior = self.W, self.b, self.mu_prior\n",
    "        K, T2 = self.W.shape\n",
    "        mu_post, loglik = np.zeros((K, N)), np.zeros((1, N))\n",
    "        sigma_post = np.zeros((K, K, N))\n",
    "        for n in range(N):\n",
    "            mu_p, sigma_p, loglik[0, n], _ = self.compute_latent_posterior_statistics(y[n, :].T)\n",
    "            mu_post[:, n] = np.squeeze(np.asarray(mu_p))\n",
    "            sigma_post[:, :, n] = np.squeeze(np.asarray(sigma_p))\n",
    "        return mu_post, sigma_post, loglik\n",
    "\n",
    "\n",
    "def sigmoid_times_gauss(X, wMAP, C):\n",
    "    vv = lambda x, y: jnp.vdot(x, y)\n",
    "    mv = vmap(vv, (None, 0), 0)\n",
    "    mm = vmap(mv, (0, None), 0)\n",
    "    vm = vmap(vv, (0, 0), 0)\n",
    "\n",
    "    mu = X @ wMAP\n",
    "    n = X.shape[1]\n",
    "    if n < 1000:\n",
    "        sigma2 = np.diag(X @ C @ X.T)\n",
    "    else:\n",
    "        sigma2 = vm(X, mm(C, X))\n",
    "    kappa = 1 / np.sqrt(1 + np.pi * sigma2 / 8)\n",
    "    p = sigmoid(kappa * mu.reshape(kappa.shape))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f677447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LATEXIFY\"] = \"\"\n",
    "os.environ[\"FIG_DIR\"] = \"figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99202c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pml.latexify(width_scale_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b28d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image to figures/binaryPCAinput_latexified.pdf\n",
      "Figure size: [3.  1.5]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "max_iter, conv_tol = 50, 1e-4\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-1 * x))\n",
    "d, k, m = 16, 3, 50\n",
    "noise_level = 0.5\n",
    "\n",
    "proto = np.random.rand(d, k) < noise_level\n",
    "src = np.concatenate((np.tile(proto[:, 0], (1, m)), np.tile(proto[:, 1], (1, m)), np.tile(proto[:, 2], (1, m))), axis=1)\n",
    "clean_data = np.concatenate(\n",
    "    (np.tile(proto[:, 0], (m, 1)), np.tile(proto[:, 1], (m, 1)), np.tile(proto[:, 2], (m, 1))), axis=0\n",
    ")\n",
    "n = clean_data.shape[0]\n",
    "\n",
    "\n",
    "mask, noisy_data, missing_data, = (\n",
    "    np.random.rand(n, d) < 0.05,\n",
    "    np.copy(clean_data),\n",
    "    np.copy(clean_data),\n",
    ")\n",
    "\n",
    "noisy_data[mask] = 1 - noisy_data[mask]\n",
    "missing_data[mask] = np.nan\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plt.imshow(noisy_data, aspect=\"auto\", interpolation=\"none\", origin=\"lower\", cmap=\"gray\")\n",
    "plt.title(\"Noisy Binary Data\")\n",
    "pml.savefig(\"binaryPCAinput\", tight_bbox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d0009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patel_karm/anaconda3/envs/py3713/lib/python3.7/site-packages/ipykernel_launcher.py:50: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image to figures/binaryPCAembedding_latexified.pdf\n",
      "Figure size: [3.  1.5]\n"
     ]
    }
   ],
   "source": [
    "MARKER_SIZE = 2\n",
    "binaryFA = BinaryFA(d, 2, 50, 1e-4, True)\n",
    "binaryFA.variational_em(noisy_data)\n",
    "\n",
    "mu_post, sigma_post, loglik = binaryFA.infer_latent(noisy_data)\n",
    "\n",
    "symbols = [\"ro\", \"gs\", \"k*\"]\n",
    "plt.figure()\n",
    "plt.plot(mu_post[0, :m], mu_post[1, 0:m], symbols[0], markersize=MARKER_SIZE)\n",
    "plt.plot(mu_post[0, m : 2 * m], mu_post[1, m : 2 * m], symbols[1], markersize=MARKER_SIZE)\n",
    "plt.plot(mu_post[0, 2 * m :], mu_post[1, 2 * m :], symbols[2], markersize=MARKER_SIZE)\n",
    "plt.title(\"Latent Embedding\")\n",
    "sns.despine()\n",
    "pml.savefig(\"binaryPCAembedding\", tight_bbox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327f1e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image to figures/binaryPCApostpred_latexified.pdf\n",
      "Figure size: [3.  1.5]\n"
     ]
    }
   ],
   "source": [
    "prob_on = binaryFA.predict_missing(noisy_data)\n",
    "plt.figure()\n",
    "plt.imshow(prob_on, aspect=\"auto\", interpolation=\"none\", origin=\"lower\", cmap=\"gray\")\n",
    "plt.title(\"Posterior Predictive\")\n",
    "pml.savefig(\"binaryPCApostpred\", tight_bbox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66837348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image to figures/binaryPCArecon_latexified.pdf\n",
      "Figure size: [3.  1.5]\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(prob_on > 0.5, aspect=\"auto\", interpolation=\"none\", origin=\"lower\", cmap=\"gray\")\n",
    "plt.title(\"Reconstruction\")\n",
    "pml.savefig(\"binaryPCArecon\", tight_bbox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9feefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3713]",
   "language": "python",
   "name": "conda-env-py3713-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
