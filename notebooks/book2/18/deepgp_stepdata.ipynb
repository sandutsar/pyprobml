{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Data using Deep Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import deepgp\n",
    "except ModuleNotFoundError:\n",
    "    %pip install git+https://github.com/SheffieldML/PyDeepGP.git\n",
    "    import deepgp\n",
    "\n",
    "try:\n",
    "    import GPy\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq GPy\n",
    "    import GPy\n",
    "\n",
    "try:\n",
    "    from probml_utils import latexify, savefig, is_latexify_enabled\n",
    "except ModuleNotFoundError:\n",
    "    %pip install git+https://github.com/probml/probml-utils.git\n",
    "    from probml_utils import latexify, savefig, is_latexify_enabled\n",
    "\n",
    "try:\n",
    "    import tinygp\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -q tinygp\n",
    "    import tinygp\n",
    "\n",
    "# import display\n",
    "import seaborn as sns\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from tinygp import kernels, GaussianProcess\n",
    "from jax.config import config\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import jaxopt\n",
    "except ModuleNotFoundError:\n",
    "    %pip install jaxopt\n",
    "    import jaxopt\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "latexify(width_scale_factor=2, fig_height=1.75)\n",
    "marksize = 3 if is_latexify_enabled() else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_low = 25\n",
    "num_high = 25\n",
    "gap = -0.1\n",
    "noise = 0.0001\n",
    "x = jnp.vstack(\n",
    "    (jnp.linspace(-1, -gap / 2.0, num_low)[:, jnp.newaxis], jnp.linspace(gap / 2.0, 1, num_high)[:, jnp.newaxis])\n",
    ").reshape(\n",
    "    -1,\n",
    ")\n",
    "y = jnp.vstack((jnp.zeros((num_low, 1)), jnp.ones((num_high, 1))))\n",
    "scale = jnp.sqrt(y.var())\n",
    "offset = y.mean()\n",
    "yhat = ((y - offset) / scale).reshape(\n",
    "    -1,\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(x, y, \"r.\", markersize=marksize)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "xlim = (-2, 2)\n",
    "ylim = (-0.6, 1.6)\n",
    "plt.ylim(ylim)\n",
    "plt.xlim(xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(theta, X, y):\n",
    "    kernel = jnp.exp(theta[\"log_amp\"]) * kernels.ExpSquared(scale=jnp.exp(theta[\"log_scale\"]))\n",
    "    gp = GaussianProcess(kernel, X, diag=jnp.exp(theta[\"log_diag\"]))\n",
    "    return -gp.log_probability(y)\n",
    "\n",
    "\n",
    "theta_init = {\"log_scale\": jnp.log(1.0), \"log_diag\": jnp.log(1.0), \"log_amp\": jnp.log(1.0)}\n",
    "obj = jax.jit(jax.value_and_grad(neg_log_likelihood))\n",
    "solver = jaxopt.ScipyMinimize(fun=neg_log_likelihood, method=\"L-BFGS-B\")\n",
    "soln = solver.run(\n",
    "    theta_init,\n",
    "    X=x,\n",
    "    y=y.reshape(\n",
    "        -1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "kernel = jnp.exp(soln.params[\"log_amp\"]) * kernels.ExpSquared(scale=jnp.exp(soln.params[\"log_scale\"]))\n",
    "gp = GaussianProcess(kernel, x, diag=jnp.exp(soln.params[\"log_diag\"]))\n",
    "\n",
    "xnew = jnp.vstack(\n",
    "    (jnp.linspace(-2, -gap / 2.0, 25)[:, jnp.newaxis], jnp.linspace(gap / 2.0, 2, 25)[:, jnp.newaxis])\n",
    ").reshape(\n",
    "    -1,\n",
    ")\n",
    "cond_gp = gp.condition(\n",
    "    y.reshape(\n",
    "        -1,\n",
    "    ),\n",
    "    xnew,\n",
    ").gp\n",
    "mu, var = cond_gp.loc, cond_gp.variance\n",
    "\n",
    "var = var + jnp.exp(soln.params[\"log_diag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting GP Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "latexify(width_scale_factor=2, fig_height=1.75)\n",
    "\n",
    "plt.plot(x, y, \"r.\", markersize=marksize)\n",
    "plt.plot(xnew, mu, \"blue\", markersize=marksize)\n",
    "plt.fill_between(\n",
    "    xnew.flatten(),\n",
    "    mu.flatten() - 1.96 * jnp.sqrt(var),\n",
    "    mu.flatten() + 1.96 * jnp.sqrt(var),\n",
    "    alpha=0.3,\n",
    "    color=\"C1\",\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "legendsize = 5 if is_latexify_enabled() else 9\n",
    "plt.legend(labels=[\"Mean\", \"Data\", \"Confidence\"], loc=(0.5, 0.2), prop={\"size\": legendsize}, frameon=False)\n",
    "# ax.title(\"$(l, \\sigma_f, \\sigma_y)=${}, {}, {}\".format(length_scale, sigma_f, sigma_y))\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "\n",
    "savefig(\"gp_stepdata_fit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 3\n",
    "latent_dim = 1\n",
    "\n",
    "kernels = [*[GPy.kern.RBF(latent_dim, ARD=True)] * num_hidden]  # hidden kernels\n",
    "kernels.append(GPy.kern.RBF(np.array(x.reshape(-1, 1)).shape[1]))  # we append a kernel for the input layer\n",
    "\n",
    "m = deepgp.DeepGP(\n",
    "    # this describes the shapes of the inputs and outputs of our latent GPs\n",
    "    [y.reshape(-1, 1).shape[1], *[latent_dim] * num_hidden, x.reshape(-1, 1).shape[1]],\n",
    "    X=np.array(x.reshape(-1, 1)),  # training input\n",
    "    Y=np.array(y.reshape(-1, 1)),  # training outout\n",
    "    inits=[*[\"PCA\"] * num_hidden, \"PCA\"],  # initialise layers\n",
    "    kernels=kernels,\n",
    "    num_inducing=x.shape[0],\n",
    "    back_constraint=False,\n",
    ")\n",
    "m.initialize_parameter()\n",
    "# display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Deep GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_dgp(model, messages=True):\n",
    "    \"\"\"Utility function for optimising deep GP by first\n",
    "    reinitiailising the Gaussian noise at each layer\n",
    "    (for reasons pertaining to stability)\n",
    "    \"\"\"\n",
    "    model.initialize_parameter()\n",
    "    for layer in model.layers:\n",
    "        layer.likelihood.variance.constrain_positive(warning=False)\n",
    "        layer.likelihood.variance = 1.0  # small variance may cause collapse\n",
    "    model.optimize(messages=messages, max_iters=10000)\n",
    "\n",
    "\n",
    "optimise_dgp(m, messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.optimize_restarts(num_restarts=5)\n",
    "mu_dgp, var_dgp = m.predict(xnew.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dgp(model, X, num_samples=1, include_likelihood=True):\n",
    "    samples = []\n",
    "    jitter = 1e-5\n",
    "    count, num_tries = 0, 100\n",
    "    while len(samples) < num_samples:\n",
    "        next_input = X\n",
    "        if count > num_tries:\n",
    "            print(\"failed to sample\")\n",
    "            break\n",
    "        try:\n",
    "            count = count + 1\n",
    "            for layer in reversed(model.layers):\n",
    "                mu_k, sig_k = layer.predict(next_input, full_cov=True, include_likelihood=include_likelihood)\n",
    "                sample_k = mu_k + np.linalg.cholesky(sig_k + jitter * np.eye(X.shape[0])) @ np.random.randn(*X.shape)\n",
    "                next_input = sample_k\n",
    "            samples.append(sample_k)\n",
    "            count = 0\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return samples if num_samples > 1 else samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Deep GP fit without samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "num = 5\n",
    "sample = sample_dgp(m, xnew.reshape(-1, 1), num, include_likelihood=False)\n",
    "latexify(width_scale_factor=2, fig_height=1.75)\n",
    "plt.plot(xnew, mu_dgp, \"blue\")\n",
    "plt.scatter(x, y, c=\"r\", s=marksize)\n",
    "plt.fill_between(\n",
    "    xnew.flatten(),\n",
    "    mu_dgp.flatten() - 1.96 * jnp.sqrt(var_dgp.flatten()),\n",
    "    mu_dgp.flatten() + 1.96 * jnp.sqrt(var_dgp.flatten()),\n",
    "    alpha=0.3,\n",
    "    color=\"C1\",\n",
    ")\n",
    "sns.despine()\n",
    "legendsize = 4.5 if is_latexify_enabled() else 9\n",
    "plt.legend(labels=[\"Mean\", \"Data\", \"Confidence\"], loc=2, prop={\"size\": legendsize}, frameon=False)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Deep GP fit with samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "latexify(width_scale_factor=2, fig_height=1.75)\n",
    "plt.plot(xnew, mu_dgp, \"b\")\n",
    "plt.scatter(x, y, c=\"r\", s=marksize)\n",
    "plt.fill_between(\n",
    "    xnew.flatten(),\n",
    "    mu_dgp.flatten() - 1.96 * jnp.sqrt(var_dgp.flatten()),\n",
    "    mu_dgp.flatten() + 1.96 * jnp.sqrt(var_dgp.flatten()),\n",
    "    alpha=0.3,\n",
    "    color=\"C1\",\n",
    ")\n",
    "plt.plot(xnew, np.array(sample).reshape(-1, num), \"k.\", markersize=3, alpha=0.3)\n",
    "sns.despine()\n",
    "legendsize = 5 if is_latexify_enabled() else 9\n",
    "plt.legend(labels=[\"Mean\", \"Data\", \"Confidence\", \"Samples\"], loc=(0.2, 0.8), prop={\"size\": legendsize}, frameon=False)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "savefig(\"deep_gp_stepdata_fit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Input to each Deep GP layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dgp_layers(model, X, training_points=True):\n",
    "    \"\"\"Plot mappings between layers in a deep GP\"\"\"\n",
    "\n",
    "    num_layers = len(model.layers)\n",
    "    layer_input = X\n",
    "\n",
    "    # The layers in a deep GP are ordered from observation to input,\n",
    "    layers_name = [\"layer1\", \"layer2\", \"layer3\"]\n",
    "    layers = list(reversed(model.layers))\n",
    "    for i, layer in enumerate(layers):\n",
    "        plt.figure()\n",
    "        latexify(width_scale_factor=2, fig_height=1.75)\n",
    "        mu_i, var_i = layer.predict(layer_input, include_likelihood=True)\n",
    "        plt.plot(layer_input, mu_i, \"blue\")\n",
    "        plt.fill_between(\n",
    "            layer_input[:, 0],\n",
    "            mu_i.flatten() - 1.96 * jnp.sqrt(var_i.flatten()),\n",
    "            mu_i.flatten() + 1.96 * jnp.sqrt(var_i.flatten()),\n",
    "            alpha=0.3,\n",
    "            color=\"C1\",\n",
    "        )\n",
    "\n",
    "        plt.ylabel(layers_name[i] if i < len(layers) - 1 else \"output\")\n",
    "        plt.xlabel(layers_name[i - 1] if i > 0 else \"input\")\n",
    "        if training_points:  # Plot propagated training points\n",
    "            plt.plot(\n",
    "                layer.X.mean.values if i > 0 else layer.X,\n",
    "                layer.Y.mean.values if i < num_layers - 1 else layer.Y,\n",
    "                \"r.\",\n",
    "                markersize=marksize,\n",
    "            )\n",
    "\n",
    "        legendsize = 6 if is_latexify_enabled() else 9\n",
    "        if i == 3:\n",
    "            plt.legend(labels=[\"Mean\", \"Confidence\", \"Data\"], loc=(0.5, 0.2), prop={\"size\": legendsize}, frameon=False)\n",
    "        sns.despine()\n",
    "        savefig(\"deep_gp_input_layer{}\".format(i + 1))\n",
    "\n",
    "\n",
    "plot_dgp_layers(m, xnew.reshape(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pyprob')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c5a0c76092399a6bd22c426573677968c7f47e4ef0855af24014a5bf1c5bd34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
