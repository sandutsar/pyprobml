{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rai2VPX7lz56"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq torch\n",
    "    import torch\n",
    "\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq tqdm\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "try:\n",
    "    from torchvision import datasets, transforms\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq torchvision\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "try:\n",
    "    from batchbald_redux import (\n",
    "        active_learning,\n",
    "        batchbald,\n",
    "        consistent_mc_dropout,\n",
    "        joint_entropy,\n",
    "        repeated_mnist,\n",
    "    )\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq batchbald_redux\n",
    "    from batchbald_redux import (\n",
    "        active_learning,\n",
    "        batchbald,\n",
    "        consistent_mc_dropout,\n",
    "        joint_entropy,\n",
    "        repeated_mnist,\n",
    "    )\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "    from probml_utils import savefig, latexify\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "    from probml_utils import savefig, latexify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBdwwnrdZtJb"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"use_cuda: {use_cuda}\")\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "kwargs = {\"num_workers\": 0, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cTyVBfGZtJb"
   },
   "outputs": [],
   "source": [
    "class BayesianCNN(consistent_mc_dropout.BayesianModule):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv1_drop = consistent_mc_dropout.ConsistentMCDropout2d()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = consistent_mc_dropout.ConsistentMCDropout2d()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc1_drop = consistent_mc_dropout.ConsistentMCDropout()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def mc_forward_impl(self, input: torch.Tensor):\n",
    "        input = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(input)), 2))\n",
    "        input = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(input)), 2))\n",
    "        input = input.view(-1, 1024)\n",
    "        input = F.relu(self.fc1_drop(self.fc1(input)))\n",
    "        input = self.fc2(input)\n",
    "        input = F.log_softmax(input, dim=1)\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pce-X38gZtJd"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CandidateBatch:\n",
    "    scores: []\n",
    "    indices: []\n",
    "\n",
    "\n",
    "def get_random(\n",
    "    log_probs_N_K_C: torch.Tensor,\n",
    "    batch_size: int,\n",
    "    num_samples: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = torch.empty(N, dtype=torch.double, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    picked_indices = torch.randperm(N)[:batch_size].numpy()\n",
    "    candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "    candidate_indices.append(picked_indices)\n",
    "    candidate_scores.append(candidate_score.item())\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHydUWKPNYfe"
   },
   "outputs": [],
   "source": [
    "batch_list = [4, 8, 16, 32]\n",
    "algo_list = [\"bald\", \"batchbald\"]\n",
    "final_test_accs = []\n",
    "final_indices = []\n",
    "\n",
    "max_training_samples = 180  # Maximum limit of train samples needed\n",
    "num_inference_samples = 100\n",
    "num_test_inference_samples = 5\n",
    "num_samples = 100000  # Total number of samples\n",
    "\n",
    "test_batch_size = 512  # Test Loader Batch size\n",
    "batch_size = 64  # Train loader Batch size\n",
    "scoring_batch_size = 128  # Pool Loader Batch size\n",
    "training_iterations = 4096 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POwMf_zCQqZ-"
   },
   "outputs": [],
   "source": [
    "for type in algo_list:\n",
    "    if type == \"bald\":\n",
    "        print(\"******************************************BALD Implementation******************************************\")\n",
    "    else:\n",
    "        print(\n",
    "            \"******************************************BatchBALD Implementation******************************************\"\n",
    "        )\n",
    "\n",
    "    for acquisition_batch_size in batch_list:  # Batch size per iteration\n",
    "        print(\n",
    "            \"******************************************Batch Size: \"\n",
    "            + str(acquisition_batch_size)\n",
    "            + \"******************************************\"\n",
    "        )\n",
    "\n",
    "        seed_value = 0\n",
    "\n",
    "        torch.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        random.seed(seed_value)\n",
    "        np.random.seed(seed_value)\n",
    "        os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
    "\n",
    "        num_initial_samples = 20  # Number of initial samples required\n",
    "        num_classes = 10  # Total classes in MNIST dataset\n",
    "\n",
    "        train_dataset, test_dataset = repeated_mnist.create_repeated_MNIST_dataset(num_repetitions=1, add_noise=False)\n",
    "\n",
    "        # Generates 20 samples (2 from each class) and returns their indices\n",
    "        initial_samples = active_learning.get_balanced_sample_indices(\n",
    "            repeated_mnist.get_targets(train_dataset),\n",
    "            num_classes=num_classes,\n",
    "            n_per_digit=num_initial_samples / num_classes,\n",
    "        )\n",
    "\n",
    "        test_accs = []\n",
    "        test_loss = []\n",
    "        added_indices = []\n",
    "\n",
    "        active_learning_data = active_learning.ActiveLearningData(\n",
    "            train_dataset\n",
    "        )  # Splits the dataset into training dataset and pool dataset\n",
    "\n",
    "        active_learning_data.acquire(\n",
    "            initial_samples\n",
    "        )  # Seperates the initial indices from the pool and fixes it as initial train dataset\n",
    "        active_learning_data.extract_dataset_from_pool(\n",
    "            40000\n",
    "        )  # Extracts 40000 samples from pool and makes it as validation dataset\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            active_learning_data.training_dataset,\n",
    "            sampler=active_learning.RandomFixedLengthSampler(\n",
    "                active_learning_data.training_dataset, training_iterations\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        pool_loader = torch.utils.data.DataLoader(\n",
    "            active_learning_data.pool_dataset,\n",
    "            batch_size=scoring_batch_size,\n",
    "            shuffle=False,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "        pbar = tqdm(\n",
    "            initial=len(active_learning_data.training_dataset),\n",
    "            total=max_training_samples,\n",
    "            desc=\"Training Set Size\",\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            model = BayesianCNN(num_classes).to(device=device)  # initialise model\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            # Train\n",
    "            for data, target in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "                data = data.to(device=device)\n",
    "                target = target.to(device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                prediction = model(data, 1).squeeze(1)\n",
    "                loss = F.nll_loss(prediction, target)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Test\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "                    data = data.to(device=device)\n",
    "                    target = target.to(device=device)\n",
    "\n",
    "                    prediction = torch.logsumexp(model(data, num_test_inference_samples), dim=1) - math.log(\n",
    "                        num_test_inference_samples\n",
    "                    )\n",
    "                    loss += F.nll_loss(prediction, target, reduction=\"sum\")\n",
    "\n",
    "                    prediction = prediction.max(1)[1]\n",
    "                    correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "            loss /= len(test_loader.dataset)\n",
    "            test_loss.append(loss)\n",
    "\n",
    "            percentage_correct = 100.0 * correct / len(test_loader.dataset)\n",
    "            test_accs.append(percentage_correct)\n",
    "\n",
    "            print(\"Test set: Average loss: {:.4f}, Accuracy: ({:.2f}%)\".format(loss, percentage_correct))\n",
    "\n",
    "            if len(active_learning_data.training_dataset) >= max_training_samples:\n",
    "                break\n",
    "\n",
    "            # Acquire pool predictions\n",
    "            N = len(active_learning_data.pool_dataset)\n",
    "            logits_N_K_C = torch.empty(\n",
    "                (N, num_inference_samples, num_classes),\n",
    "                dtype=torch.double,\n",
    "                pin_memory=use_cuda,\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                for i, (data, _) in enumerate(tqdm(pool_loader, desc=\"Evaluating Acquisition Set\", leave=False)):\n",
    "                    data = data.to(device=device)\n",
    "\n",
    "                    lower = i * pool_loader.batch_size\n",
    "                    upper = min(lower + pool_loader.batch_size, N)\n",
    "                    logits_N_K_C[lower:upper].copy_(model(data, num_inference_samples).double(), non_blocking=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if type == \"batchbald\":\n",
    "                    candidate_batch = batchbald.get_batchbald_batch(\n",
    "                        logits_N_K_C,\n",
    "                        acquisition_batch_size,\n",
    "                        num_samples,\n",
    "                        dtype=torch.double,\n",
    "                        device=device,  # Returns the indices and scores(Mutual Information) for the batch selected by Batchbald/BALD Strategy.\n",
    "                    )\n",
    "\n",
    "                elif type == \"bald\":\n",
    "                    candidate_batch = batchbald.get_bald_batch(\n",
    "                        logits_N_K_C,\n",
    "                        acquisition_batch_size,\n",
    "                        dtype=torch.double,\n",
    "                        device=device,\n",
    "                    )\n",
    "\n",
    "            targets = repeated_mnist.get_targets(active_learning_data.pool_dataset)  # Returns the target labels\n",
    "            dataset_indices = active_learning_data.get_dataset_indices(\n",
    "                candidate_batch.indices\n",
    "            )  # Returns indices for candidate batch\n",
    "\n",
    "            print(\"Dataset indices: \", dataset_indices)\n",
    "            # print(\"Scores: \", candidate_batch.scores)\n",
    "            print(\"Labels: \", targets[candidate_batch.indices])\n",
    "\n",
    "            active_learning_data.acquire(candidate_batch.indices)  # add the new indices to training dataset\n",
    "            added_indices.append(dataset_indices)\n",
    "            pbar.update(len(dataset_indices))\n",
    "        final_test_accs.append(test_accs)\n",
    "        final_indices.append(added_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNS0EvPERvKf"
   },
   "outputs": [],
   "source": [
    "print(final_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoKZeD3NVxLa"
   },
   "outputs": [],
   "source": [
    "latexify(width_scale_factor=2, fig_height=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No-Rpnevc6pM"
   },
   "source": [
    "# BALD Test Accuracy Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "492b7LXsaY0P"
   },
   "outputs": [],
   "source": [
    "p = plt.rcParams\n",
    "p[\"axes.grid\"] = True\n",
    "p[\"grid.color\"] = \"#999999\"\n",
    "p[\"grid.linestyle\"] = \"--\"\n",
    "p[\"lines.linewidth\"] = 2\n",
    "\n",
    "plt.plot(np.arange(0, 132, 4), final_test_accs[0][:33], label=\"4\")\n",
    "plt.plot(np.arange(0, 132, 8), final_test_accs[1][:17], label=\"8\")\n",
    "plt.plot(np.arange(0, 132, 16), final_test_accs[2][:9], label=\"16\")\n",
    "plt.plot(np.arange(0, 132, 32), final_test_accs[3][:-1], label=\"32\")\n",
    "plt.legend()\n",
    "plt.legend(title=\"Batch-Size\", loc=\"lower right\")\n",
    "plt.xlabel(\"No. of Points Queried\", fontsize=9)\n",
    "plt.ylabel(\"Test Accuracy\", fontsize=9)\n",
    "plt.xticks([i for i in range(0, 132, 16)], rotation=90)\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "savefig(\"test_accuracy_bald\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lidifvlFc4Gt"
   },
   "source": [
    "# BatchBALD Test Accuracy Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fa0G2iqkcyBH"
   },
   "outputs": [],
   "source": [
    "p = plt.rcParams\n",
    "p[\"axes.grid\"] = True\n",
    "p[\"grid.color\"] = \"#999999\"\n",
    "p[\"grid.linestyle\"] = \"--\"\n",
    "p[\"lines.linewidth\"] = 2\n",
    "\n",
    "plt.plot(np.arange(0, 132, 4), final_test_accs[4][:33], label=\"4\")\n",
    "plt.plot(np.arange(0, 132, 8), final_test_accs[5][:17], label=\"8\")\n",
    "plt.plot(np.arange(0, 132, 16), final_test_accs[6][:9], label=\"16\")\n",
    "plt.plot(np.arange(0, 132, 32), final_test_accs[7][:-1], label=\"32\")\n",
    "plt.legend()\n",
    "plt.legend(title=\"Batch-Size\", loc=\"lower right\")\n",
    "plt.xlabel(\"No. of Points Queried\", fontsize=9)\n",
    "plt.ylabel(\"Test Accuracy\", fontsize=9)\n",
    "plt.xticks([i for i in range(0, 132, 16)], rotation=90)\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "savefig(\"test_accuracy_batchbald\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PFn02t9VxLj"
   },
   "outputs": [],
   "source": [
    "latexify(width_scale_factor=3, fig_height=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XNZG3NQcJIK"
   },
   "source": [
    "# BALD Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XT28W1YmdtcB"
   },
   "outputs": [],
   "source": [
    "rows = [\"Batch {}\".format(row) for row in [1, 2, 3]]\n",
    "plt.rcParams[\"axes.titlesize\"] = 10\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4)\n",
    "plot_indices = [final_indices[0][i][j] for i in range(4, 7) for j in range(0, 4)]\n",
    "\n",
    "for i, ax in zip(range(1, 4 * 3 + 1), axes.flatten()):\n",
    "    image = train_dataset[plot_indices[i - 1]][0].reshape((28, 28))\n",
    "    ax.imshow(image, cmap=\"gray\")\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        labelsize=0,\n",
    "        length=0,\n",
    "        left=False,\n",
    "        bottom=False,\n",
    "        labelleft=False,\n",
    "        labelbottom=False,\n",
    "    )\n",
    "for ax, row in zip(axes[:, 0], rows):\n",
    "    ax.set_ylabel(row, rotation=90, size=\"large\")\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "savefig(\"bald_samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktXAMgv1cLnZ"
   },
   "source": [
    "#BatchBALD Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ac1jMrqDcGen"
   },
   "outputs": [],
   "source": [
    "rows = [\"Batch {}\".format(row) for row in [1, 2, 3]]\n",
    "plt.rcParams[\"axes.titlesize\"] = 10\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4)\n",
    "plot_indices = [final_indices[4][i][j] for i in range(0, 3) for j in range(0, 4)]\n",
    "\n",
    "for i, ax in zip(range(1, 4 * 3 + 1), axes.flatten()):\n",
    "    image = train_dataset[plot_indices[i - 1]][0].reshape((28, 28))\n",
    "    ax.imshow(image, cmap=\"gray\")\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        labelsize=0,\n",
    "        length=0,\n",
    "        left=False,\n",
    "        bottom=False,\n",
    "        labelleft=False,\n",
    "        labelbottom=False,\n",
    "    )\n",
    "for ax, row in zip(axes[:, 0], rows):\n",
    "    ax.set_ylabel(row, rotation=90, size=\"large\")\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "savefig(\"batchbald_samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USv_-CM9cTQN"
   },
   "source": [
    "# Random Acquisition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQt0wEW2TGbx"
   },
   "outputs": [],
   "source": [
    "final_random_accs = []\n",
    "for i in range(5):\n",
    "    torch.manual_seed(i)\n",
    "    torch.cuda.manual_seed(i)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(i)\n",
    "    np.random.seed(i)\n",
    "\n",
    "    max_training_samples = 148  # Maximum limit of train samples needed\n",
    "    acquisition_batch_size = 4  # Batch size per iteration\n",
    "\n",
    "    labels_list = []\n",
    "    select_indices = []\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    active_learning_data = active_learning.ActiveLearningData(train_dataset)\n",
    "\n",
    "    # Split off the initial samples first.\n",
    "    active_learning_data.acquire(initial_samples)  # Initial train\n",
    "\n",
    "    # THIS REMOVES MOST OF THE POOL DATA. UNCOMMENT THIS TO TAKE ALL UNLABELLED DATA INTO ACCOUNT!\n",
    "    active_learning_data.extract_dataset_from_pool(40000)  ## Validation data\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        active_learning_data.training_dataset,\n",
    "        sampler=active_learning.RandomFixedLengthSampler(active_learning_data.training_dataset, training_iterations),\n",
    "        batch_size=batch_size,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    pool_loader = torch.utils.data.DataLoader(\n",
    "        active_learning_data.pool_dataset,\n",
    "        batch_size=scoring_batch_size,\n",
    "        shuffle=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Run experiment\n",
    "    test_accs = []\n",
    "    test_loss = []\n",
    "    added_indices = []\n",
    "\n",
    "    pbar = tqdm(\n",
    "        initial=len(active_learning_data.training_dataset),\n",
    "        total=max_training_samples,\n",
    "        desc=\"Training Set Size\",\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        model = BayesianCNN(num_classes).to(device=device)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # Train\n",
    "        for data, target in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            prediction = model(data, 1).squeeze(1)\n",
    "            loss = F.nll_loss(prediction, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Test\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "                data = data.to(device=device)\n",
    "                target = target.to(device=device)\n",
    "\n",
    "                prediction = torch.logsumexp(model(data, num_test_inference_samples), dim=1) - math.log(\n",
    "                    num_test_inference_samples\n",
    "                )\n",
    "                loss += F.nll_loss(prediction, target, reduction=\"sum\")\n",
    "\n",
    "                prediction = prediction.max(1)[1]\n",
    "                correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "        loss /= len(test_loader.dataset)\n",
    "        test_loss.append(loss)\n",
    "\n",
    "        percentage_correct = 100.0 * correct / len(test_loader.dataset)\n",
    "        test_accs.append(percentage_correct)\n",
    "\n",
    "        print(\n",
    "            \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(\n",
    "                loss, correct, len(test_loader.dataset), percentage_correct\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(active_learning_data.training_dataset) >= max_training_samples:\n",
    "            break\n",
    "\n",
    "        # Acquire pool predictions\n",
    "        N = len(active_learning_data.pool_dataset)\n",
    "        logits_N_K_C = torch.empty(\n",
    "            (N, num_inference_samples, num_classes),\n",
    "            dtype=torch.double,\n",
    "            pin_memory=use_cuda,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for i, (data, _) in enumerate(tqdm(pool_loader, desc=\"Evaluating Acquisition Set\", leave=False)):\n",
    "                data = data.to(device=device)\n",
    "\n",
    "                lower = i * pool_loader.batch_size\n",
    "                upper = min(lower + pool_loader.batch_size, N)\n",
    "                logits_N_K_C[lower:upper].copy_(model(data, num_inference_samples).double(), non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            candidate_batch = get_random(\n",
    "                logits_N_K_C,\n",
    "                acquisition_batch_size,\n",
    "                num_samples,\n",
    "                dtype=torch.double,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "        targets = repeated_mnist.get_targets(active_learning_data.pool_dataset)\n",
    "        dataset_indices = active_learning_data.get_dataset_indices(candidate_batch.indices)\n",
    "\n",
    "        print(\"Dataset indices: \", dataset_indices)\n",
    "        print(\"Scores: \", candidate_batch.scores)\n",
    "        print(\"Labels: \", targets[candidate_batch.indices])\n",
    "        labels_list.append(targets[candidate_batch.indices])\n",
    "        select_indices.append(dataset_indices)\n",
    "        active_learning_data.acquire(candidate_batch.indices)\n",
    "        added_indices.append(dataset_indices)\n",
    "        pbar.update(len(dataset_indices))\n",
    "    final_random_accs.append(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8hGLo58a8od"
   },
   "outputs": [],
   "source": [
    "random_scores_array = np.array(final_random_accs)\n",
    "random_mean = np.mean(random_scores_array, axis=0)\n",
    "random_std = np.std(random_scores_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYwsJA1ha_XU"
   },
   "outputs": [],
   "source": [
    "p = plt.rcParams\n",
    "p[\"axes.grid\"] = True\n",
    "p[\"grid.color\"] = \"#999999\"\n",
    "p[\"grid.linestyle\"] = \"--\"\n",
    "\n",
    "p[\"lines.linewidth\"] = 2\n",
    "plt.plot(np.arange(0, 100, acquisition_batch_size), random_mean[:25], label=\"Random\")\n",
    "plt.fill_between(\n",
    "    np.arange(0, 100, acquisition_batch_size),\n",
    "    random_mean[:25] - random_std[:25],\n",
    "    random_mean[:25] + random_std[:25],\n",
    "    color=\"lightskyblue\",\n",
    ")\n",
    "plt.plot(np.arange(0, 100, acquisition_batch_size), final_test_accs[0][:25], label=\"BALD\")\n",
    "plt.plot(\n",
    "    np.arange(0, 100, acquisition_batch_size),\n",
    "    final_test_accs[4][:25],\n",
    "    label=\"BatchBALD\",\n",
    ")\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=7)\n",
    "plt.xlabel(\"No. of Points Queried\", fontsize=10)\n",
    "plt.ylabel(\"Test Accuracy\", fontsize=10)\n",
    "plt.xticks([i for i in range(0, 100, 16)], rotation=90)\n",
    "plt.yticks([i for i in range(55, 95, 5)], rotation=90)\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "savefig(\"accuracy_comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1N64QIkXZtJx"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "batch_bald_mnist_pytorch.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.13 ('colab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fab030fa160548906f6ab3a2d16d6b1d768a5fb51cf943bc7809d52d99a9b269"
   }
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}